{"meta":{"title":"YangWC's Blog","subtitle":null,"description":"Personal blog website.","author":"WC Yang","url":"http://yoursite.com","root":"/"},"pages":[{"title":"404 Not Found","date":"2019-04-27T07:26:21.624Z","updated":"2019-04-27T07:26:21.624Z","comments":true,"path":"404.html","permalink":"http://yoursite.com/404.html","excerpt":"","text":"**404 Not Found** **�ܱ�Ǹ�������ʵ�ҳ�治����** �����������ַ�����õ�ַ�ѱ�ɾ��"},{"title":"关于","date":"2019-04-27T10:20:23.860Z","updated":"2019-04-27T10:20:23.860Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"[](https://github.com/ZeusYang) 中山大学本科四年级 计算机科学与技术专业 准研究生，研究方向计算机图形学 现居广州大学城 关于本站欢迎来到 YangWC 的博客！本站会记录自己的一些学习内容，如若有错，欢迎指正，感谢！ 关于主题本站的主题风格是：Material X有任何问题请留言。"},{"title":"大佬的博客","date":"2019-04-27T10:52:08.692Z","updated":"2019-04-27T10:52:08.692Z","comments":true,"path":"friends/index.html","permalink":"http://yoursite.com/friends/index.html","excerpt":"","text":"名称： YangWC’s Blog头像： https://cdn.jsdelivr.net/gh/ZeusYang/CDN-for-yangwc.com@1.1.4//globalImage/avator.jpg网址： https://yangwc.com"},{"title":"所有分类","date":"2019-04-27T08:54:04.778Z","updated":"2019-04-27T08:54:04.778Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2019-04-27T08:02:52.306Z","updated":"2019-04-27T08:02:52.306Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"软渲染器Soft Renderer：进击三维篇","slug":"SoftRenderer-3DPipeline","date":"2019-05-02T06:26:22.186Z","updated":"2019-05-02T06:25:54.036Z","comments":true,"path":"2019/05/02/SoftRenderer-3DPipeline/","link":"","permalink":"http://yoursite.com/2019/05/02/SoftRenderer-3DPipeline/","excerpt":"有了自己实现好的的3D数学库和一个基本的光栅化渲染框架，就可以开始向这个渲染框架填充内容了。本章内容主要关于3维渲染管线的实现、深度测试、背面剔除、几何裁剪、透视纹理映射，这些内容早已被渲染API集成。学习和实现这些算法，是为了彻底了解三维物体的整个渲染流程。注意：初学者慎入","text":"有了自己实现好的的3D数学库和一个基本的光栅化渲染框架，就可以开始向这个渲染框架填充内容了。本章内容主要关于3维渲染管线的实现、深度测试、背面剔除、几何裁剪、透视纹理映射，这些内容早已被渲染API集成。学习和实现这些算法，是为了彻底了解三维物体的整个渲染流程。注意：初学者慎入 进入三维世界 裁剪、剔除优化 透视纹理映射、采样 程序结果 进入三维世界&emsp;&emsp;尽管二维的屏幕只能显示二维的像素，但是我们可以通过将三维的物体变换到二维的屏幕上，从而渲染出三维空间的一个投影面。这与我们人类的视觉系统类似，视网膜上最终获取的也只是三维空间某个角度下的投影。为了让三维物体正确地显示到屏幕上，我们需要借助一系列的坐标空间变换。 坐标系统&emsp;&emsp;在渲染管线中，三维物体的顶点在最终转换为屏幕坐标之前会被变换到多个坐标系统，这其中有几个过渡性的坐标系，使得整个变换流程逻辑清晰、便于理解。此外在某些特定情况下在这些特定的坐标系中，一些操作更加容易、方便和灵活。通常，渲染管线有$5$个不同的坐标系统，分别是局部空间、世界空间、视觉空间、裁剪空间和屏幕空间，以下是LearnOpenGL CN)的原话： 局部坐标是对象相对于局部原点的坐标，也是物体起始的坐标。 下一步是将局部坐标变换为世界空间坐标，世界空间坐标是处于一个更大的空间范围的。这些坐标相对于世界的全局原点，它们会和其它物体一起相对于世界的原点进行摆放。 接下来我们将世界坐标变换为观察空间坐标，使得每个坐标都是从摄像机或者说观察者的角度进行观察的。 坐标到达观察空间之后，我们需要将其投影到裁剪坐标。裁剪坐标会被处理至-1.0到1.0的范围内，并判断哪些顶点将会出现在屏幕上。 最后，我们将裁剪坐标变换为屏幕坐标，我们将使用一个叫做视口变换(Viewport Transform)的过程。视口变换将位于-1.0到1.0范围的坐标变换到由glViewport函数所定义的坐标范围内。最后变换出来的坐标将会送到光栅器，将其转化为片段 &emsp;&emsp;通过以上的几个步骤，三维的物体坐标最终变换到了屏幕的坐标上，其中视图矩阵和投影矩阵的构建较为复杂一点，前面我的博文软渲染器Soft Renderer：3D数学篇已经推导过这两个矩阵，这里就不再赘述了。若想查看更多关于坐标系统的内容，请查看LearnOpenGL CN的这篇文章：坐标系统)。坐标变换是一般发生在顶点着色器以及顶点着色器输出到光栅化这一阶段，视口变换在顶点着色器输出之后，不在着色器中进行（视口变换已经在前面的光栅化篇提到过了）。所以为了实现坐标变换，我们的着色器要存储$model$、$view$、$project$这三个矩阵，在$SimpleShader$中添加相关的成员变量及方法： 1234567891011121314151617181920212223242526272829class SimpleShader : public BaseShader&#123;private: Matrix4x4 m_modelMatrix; Matrix4x4 m_viewMatrix; Matrix4x4 m_projectMatrix;public: ...... virtual void setModelMatrix(const Matrix4x4 &amp;world); virtual void setViewMatrix(const Matrix4x4 &amp;view); virtual void setProjectMatrix(const Matrix4x4 &amp;project);&#125;;void SimpleShader::setModelMatrix(const Matrix4x4 &amp;world)&#123; m_modelMatrix = world;&#125;void SimpleShader::setViewMatrix(const Matrix4x4 &amp;view)&#123; m_viewMatrix = view;&#125;void SimpleShader::setProjectMatrix(const Matrix4x4 &amp;project)&#123; m_projectMatrix = project;&#125; &emsp;&emsp;这样外部要渲染时，应该向着色器输入这三个矩阵。然后在我们的顶点着色器中填入相关的逻辑： 12345678910VertexOut SimpleShader::vertexShader(const Vertex &amp;in)&#123; VertexOut result; result.posTrans = m_modelMatrix * in.position; result.posH = m_projectMatrix * m_viewMatrix * result.posTrans; result.color = in.color; result.normal = in.normal; result.texcoord = in.texcoord; return result;&#125; &emsp;&emsp;$VertexOut$是前面文章定义的顶点着色器输出的类，它存储投影后的顶点$posH$、世界空间中的顶点$posTrans$、物体的颜色、顶点法线以及纹理坐标。接着在视口变换并送入光栅化部件之前执行透视除法，即直接将裁剪空间的顶点坐标除以它的第四个分量$w$即可。然后我们在外部的渲染循环中设置模型矩阵、视图矩阵已经投影矩阵，就能显示出三维的立体感了，以我们前一章画的三角形为例（gif录制的好像有bug，出现绿色它就给我录制成这个模糊的鬼样，实际上是非常清晰，不是渲染的锅）。 &emsp;&emsp;进入3D世界，怎么能少了3D渲染的”hello world!”——立方体呢？在$Mesh.h$手动创建一个立方体的网格数据，然后用立方体替换掉上面丑陋的三角形： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154void Mesh::asBox(double width, double height, double depth)&#123; vertices.resize(24); indices.resize(36); float halfW = width * 0.5f; float halfH = height * 0.5f; float halfD = depth * 0.5f; //front vertices[0].position = Vector3D(halfW, halfH, halfD); vertices[0].normal = Vector3D(0.f, 0.f, 1.f); vertices[0].color = Vector4D(1.f, 0.f, 0.f, 1.f); vertices[0].texcoord = Vector2D(1.f, 1.f); vertices[1].position = Vector3D(-halfW, halfH, halfD); vertices[1].normal = Vector3D(0.f, 0.f, 1.f); vertices[1].color = Vector4D(0.f, 1.f, 0.f, 1.f); vertices[1].texcoord = Vector2D(0.f, 1.f); vertices[2].position = Vector3D(-halfW,-halfH, halfD); vertices[2].normal = Vector3D(0.f, 0.f, 1.f); vertices[2].color = Vector4D(0.f, 0.f, 1.f, 1.f); vertices[2].texcoord = Vector2D(0.f, 0.f); vertices[3].position = Vector3D(halfW, -halfH, halfD); vertices[3].normal = Vector3D(0.f, 0.f, 1.f); vertices[3].color = Vector4D(0.f, 1.f, 1.f, 1.f); vertices[3].texcoord = Vector2D(1.f, 0.f); //left vertices[4].position = Vector3D(-halfW, +halfH, halfD); vertices[4].normal = Vector3D(-1.f, 0.f, 0.f); vertices[4].color = Vector4D(0.f, 0.f, 1.f, 1.f); vertices[4].texcoord = Vector2D(1.f, 1.f); vertices[5].position = Vector3D(-halfW, +halfH, -halfD); vertices[5].normal = Vector3D(-1.f, 0.f, 0.f); vertices[5].color = Vector4D(1.f, 1.f, 0.f, 1.f); vertices[5].texcoord = Vector2D(0.f, 1.f); vertices[6].position = Vector3D(-halfW, -halfH, -halfD); vertices[6].normal = Vector3D(-1.f, 0.f, 0.f); vertices[6].color = Vector4D(0.f, 1.f, 0.f, 1.f); vertices[6].texcoord = Vector2D(0.f, 0.f); vertices[7].position = Vector3D(-halfW, -halfH, halfD); vertices[7].normal = Vector3D(-1.f, 0.f, 0.f); vertices[7].color = Vector4D(1.f, 1.f, 1.f, 1.f); vertices[7].texcoord = Vector2D(1.f, 0.f); //back vertices[8].position = Vector3D(-halfW, +halfH, -halfD); vertices[8].normal = Vector3D(0.f, 0.f, -1.f); vertices[8].color = Vector4D(1.f, 0.f, 1.f, 1.f); vertices[8].texcoord = Vector2D(0.f, 0.f); vertices[9].position = Vector3D(+halfW, +halfH, -halfD); vertices[9].normal = Vector3D(0.f, 0.f, -1.f); vertices[9].color = Vector4D(0.f, 1.f, 1.f, 1.f); vertices[9].texcoord = Vector2D(1.f, 0.f); vertices[10].position = Vector3D(+halfW, -halfH, -halfD); vertices[10].normal = Vector3D(0.f, 0.f, -1.f); vertices[10].color = Vector4D(1.f, 1.f, 0.f, 1.f); vertices[10].texcoord = Vector2D(1.f, 1.f); vertices[11].position = Vector3D(-halfW, -halfH, -halfD); vertices[11].normal = Vector3D(0.f, 0.f, -1.f); vertices[11].color = Vector4D(0.f, 0.f, 1.f, 1.f); vertices[11].texcoord = Vector2D(0.f, 1.f); //right vertices[12].position = Vector3D(halfW, +halfH, -halfD); vertices[12].normal = Vector3D(1.f, 0.f, 0.f); vertices[12].color = Vector4D(0.f, 1.f, 0.f, 1.f); vertices[12].texcoord = Vector2D(0.f, 0.f); vertices[13].position = Vector3D(halfW, +halfH, +halfD); vertices[13].normal = Vector3D(1.f, 0.f, 0.f); vertices[13].color = Vector4D(1.f, 0.f, 0.f, 1.f); vertices[13].texcoord = Vector2D(1.f, 0.f); vertices[14].position = Vector3D(halfW, -halfH, +halfD); vertices[14].normal = Vector3D(1.f, 0.f, 0.f); vertices[14].color = Vector4D(0.f, 1.f, 1.f, 1.f); vertices[14].texcoord = Vector2D(1.f, 1.f); vertices[15].position = Vector3D(halfW, -halfH, -halfD); vertices[15].normal = Vector3D(1.f, 0.f, 0.f); vertices[15].color = Vector4D(1.f, 0.f, 1.f, 1.f); vertices[15].texcoord = Vector2D(0.f, 1.f); //top vertices[16].position = Vector3D(+halfW, halfH, -halfD); vertices[16].normal = Vector3D(0.f, 1.f, 0.f); vertices[16].color = Vector4D(0.f, 0.f, 0.f, 1.f); vertices[16].texcoord = Vector2D(0.f, 0.f); vertices[17].position = Vector3D(-halfW, halfH, -halfD); vertices[17].normal = Vector3D(0.f, 1.f, 0.f); vertices[17].color = Vector4D(1.f, 1.f, 0.f, 1.f); vertices[17].texcoord = Vector2D(1.f, 0.f); vertices[18].position = Vector3D(-halfW, halfH, halfD); vertices[18].normal = Vector3D(0.f, 1.f, 0.f); vertices[18].color = Vector4D(0.f, 1.f, 1.f, 1.f); vertices[18].texcoord = Vector2D(1.f, 1.f); vertices[19].position = Vector3D(+halfW, halfH, halfD); vertices[19].normal = Vector3D(0.f, 1.f, 0.f); vertices[19].color = Vector4D(1.f, 0.f, 0.f, 1.f); vertices[19].texcoord = Vector2D(0.f, 1.f); //down vertices[20].position = Vector3D(+halfW, -halfH, -halfD); vertices[20].normal = Vector3D(0.f, -1.f, 0.f); vertices[20].color = Vector4D(0.f, 0.f, 1.f, 1.f); vertices[20].texcoord = Vector2D(0.f, 0.f); vertices[21].position = Vector3D(+halfW, -halfH, +halfD); vertices[21].normal = Vector3D(0.f, -1.f, 0.f); vertices[21].color = Vector4D(1.f, 1.f, 1.f, 1.f); vertices[21].texcoord = Vector2D(1.f, 0.f); vertices[22].position = Vector3D(-halfW, -halfH, +halfD); vertices[22].normal = Vector3D(0.f, -1.f, 0.f); vertices[22].color = Vector4D(0.f, 1.f, 0.f, 1.f); vertices[22].texcoord = Vector2D(1.f, 1.f); vertices[23].position = Vector3D(-halfW, -halfH, -halfD); vertices[23].normal = Vector3D(0.f, -1.f, 0.f); vertices[23].color = Vector4D(1.f, 0.f, 1.f, 1.f); vertices[23].texcoord = Vector2D(0.f, 1.f); //front indices[0] = 0; indices[1] = 1; indices[2] = 2; indices[3] = 0; indices[4] = 2; indices[5] = 3; //left indices[6] = 4; indices[7] = 5; indices[8] = 6; indices[9] = 4; indices[10] = 6; indices[11] = 7; //back indices[12] = 8; indices[13] = 9; indices[14] = 10; indices[15] = 8; indices[16] = 10; indices[17] = 11; //right indices[18] = 12; indices[19] = 13; indices[20] = 14; indices[21] = 12; indices[22] = 14; indices[23] = 15; //top indices[24] = 16; indices[25] = 17; indices[26] = 18; indices[27] = 16; indices[28] = 18; indices[29] = 19; //down indices[30] = 20; indices[31] = 21; indices[32] = 22; indices[33] = 20; indices[34] = 22; indices[35] = 23;&#125; &emsp;&emsp;结果我们就得到一个如下面所示的奇怪的立方体： &emsp;&emsp;下面是动图gif（再重复一遍，模糊不是渲染的锅）： &emsp;&emsp;这的确有点像是一个立方体，但又有种说不出的奇怪。立方体的某些本应被遮挡住的面被绘制在了这个立方体其他面之上。出现这样结果的原因是因为我们的软渲染器是对一个一个三角形进行绘制的，而且计算像素时时直接覆盖而不管这个像素是否已经有其他值了，所以一个像素的值完全取决于最后赋予它的$RGBA$。除非渲染管线自动按照从远到近的顺序（这类算法有画家算法、空间分割BSP树算法）绘制三角形，否则直接覆盖的方法获取不了正确的像素值。正确渲染结果应该是像素的$RGBA$值为最靠近视点的片元值，一种常用的技术是借助第三维信息——深度来对每个相同位置的不同片元做深度的比较，并且取深度较低的那一个。 深度测试&emsp;&emsp;为了获取正确的三维渲染结果，我们采用一种深度缓冲的技术。深度缓冲存储深度信息，它的分辨率应该与颜色缓冲一致，深度值存储在每个片段里面（作为片段的z值），当片段想要输出它的颜色时，我们将它的深度值和z缓冲进行比较，如果当前的片段在其它片段之后，它将会被丢弃，否则将会覆盖。这个过程称为深度测试。在OpenGL和DirectX这些渲染API中，深度缓冲会自动执行而无需用户操作。在我们的软渲染器中，我们自己实现一个这样的深度测试，算法原理很简单，但是效果非常不错！ &emsp;&emsp;深度缓冲通常和颜色缓冲一起，作为帧缓冲的附件，我们在帧缓冲类中增加深度缓冲相关的变量、方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class FrameBuffer&#123;private: ...... std::vector&lt;double&gt; m_depthBuffer;public: ...... void clearColorAndDepthBuffer(const Vector4D &amp;color); double getDepth(const unsigned int &amp;x, const unsigned int &amp;y)const; void drawDepth(const unsigned int &amp;x, const unsigned int &amp;y, const double &amp;value);&#125;;void FrameBuffer::clearColorAndDepthBuffer(const Vector4D &amp;color)&#123; // fill the color buffer and depth buffer. unsigned char red = static_cast&lt;unsigned char&gt;(255*color.x); unsigned char green = static_cast&lt;unsigned char&gt;(255*color.y); unsigned char blue = static_cast&lt;unsigned char&gt;(255*color.z); unsigned char alpha = static_cast&lt;unsigned char&gt;(255*color.w); for(unsigned int row = 0;row &lt; m_height;++ row) &#123; for(unsigned int col = 0;col &lt; m_width;++ col) &#123; m_depthBuffer[row*m_width+col] = 1.0f; ...... &#125; &#125;&#125;double FrameBuffer::getDepth(const unsigned int &amp;x, const unsigned int &amp;y) const&#123; if(x &lt; 0 || x &gt;= m_width || y &lt; 0 || y &gt;= m_height) return 0.0f; return m_depthBuffer[y*m_width+x];&#125;void FrameBuffer::drawDepth(const unsigned int &amp;x, const unsigned int &amp;y, const double &amp;value)&#123; if(x &lt; 0 || x &gt;= m_width || y &lt; 0 || y &gt;= m_height) return; unsigned int index = y*m_width + x; m_depthBuffer[index] = value;&#125; &emsp;&emsp;然后我们对于每一个片元，我们获取深度缓冲中相应的数值并进行比较。在这之前，我们还要简单回顾一下在透视投影矩阵中深度值的非线性映射，在前面的数学篇中我们知道透视投影矩阵有如下形式： M_{projection}= \\left( \\begin{matrix} \\frac{1}{aspect*tan(fovy/2)}&0&0&0\\\\ 0&\\frac{1}{tan(fovy/2)}&0&0\\\\ 0&0&-\\frac{f+n}{f-n}&-\\frac{2fn}{f-n}\\\\ 0&0&-1&0 \\end{matrix} \\right)&emsp;&emsp;因而视图空间中的深度信息$z_e$和标准化设备空间中的深度信息$z_n$关系为： z_n=(-\\frac{f+n}{f-n}z_e-\\frac{2fn}{f-n})/{-z_e} =\\frac{2fn}{z_e(f-n)}+\\frac{f+n}{f-n} \\tag {1}&emsp;&emsp;可以看到$z_e$d到$z_n$是一种从$[-f, -n]$到$[-1,1]$的非线性映射。当$z_e$比较小的时候，公式$(1)$有很高的精度；当$z_e$比较大的时候，公式$(1)$应为取值精度降低。这个关系可以直观地从下图的函数曲线看出来： &emsp;&emsp;可以看到，深度值很大一部分是由很小的z值所决定的，这给了近处的物体很大的深度精度。$z_n$取值为$[-1,1]$，我们最后将其简单地映射到$[0,1]$，这一步我放在透视除法后。 123456789void Pipeline::perspectiveDivision(VertexOut &amp;target)&#123; target.posH.x /= target.posH.w; target.posH.y /= target.posH.w; target.posH.z /= target.posH.w; target.posH.w = 1.0f; // map from [-1,1] to [0,1] target.posH.z = (target.posH.z+1.0f) * 0.5f;&#125; &emsp;&emsp;在写入深度缓冲之前应该要清除上一帧的深度缓冲，全部置$1.0f$即可，我把这一步和清除颜色缓冲放一起了，即前面的帧缓冲类的$clearColorAndDepthBuffer$方法。在光栅化步骤，获取每个片元的屏幕位置，查找深度缓并比较，若小于当前深度缓冲中获取的值，则通过深度测试并写入深度缓冲。 12345678910111213141516171819202122232425262728void Pipeline::scanLinePerRow(const VertexOut &amp;left, const VertexOut &amp;right)&#123; // scan the line from left to right. VertexOut current; int length = right.posH.x - left.posH.x + 1; for(int i = 0;i &lt;= length;++i) &#123; // linear interpolation double weight = static_cast&lt;double&gt;(i)/length; current = lerp(left, right, weight); current.posH.x = left.posH.x + i; current.posH.y = left.posH.y; // depth testing. double depth = m_backBuffer-&gt;getDepth(current.posH.x, current.posH.y); if(current.posH.z &gt; depth) continue;// fail to pass the depth testing. m_backBuffer-&gt;drawDepth(current.posH.x,current.posH.y,current.posH.z); double w = 1.0/current.oneDivZ; current.posTrans *= w; current.color *= w; current.texcoord *= w; // fragment shader m_backBuffer-&gt;drawPixel(current.posH.x, current.posH.y, m_shader-&gt;fragmentShader(current)); &#125;&#125; &emsp;&emsp;然后就可以根据深度信息正确地渲染出三维的立体感了。 裁剪、剔除优化&emsp;&emsp;目前目前我们已经构建出三维的渲染管线，但是这还不够，因为图形渲染计算量很大，通常我们需要做一些优化。常见的嵌入在渲染管线中的优化算法有几何裁剪、背面剔除。 几何裁剪&emsp;&emsp;注意在坐标系统的变换过程中，位于视锥体内的顶点坐标各分量都会被映射到$[-1,1]$的范围内，超出视锥体的顶点则被映射到超出$[-1,1]$的范围。我们在这个基础上的做相关的裁剪，注意在透视除法之前各分量实际上是处于$[-w,w]$的范围内的，这里的$w$就是该顶点坐标的第四个分量$w$。针对线框模式渲染和填充模式渲染，我们有两种不同的裁剪算法。 Cohen-Sutherland线条裁剪算法&emsp;&emsp;一条线段在视口内的情况有如下所示的四种。其中端点完全在视口内和一端在视口内而另一端是在视口外的情况很好判断，但是线段完全在视口外就没那么简单了。可以看到线段$GH$的端点都在视口外部，但是线段的一部分却在视口的内部，这是如果直接根据两个端点是否在视口外做剔除的话会导致在边缘部分的线段直接消失，得到错误的结果。一种暴力的解法就是计算线段与视口窗口的交点，但是这并不高效。 &emsp;&emsp;Cohen-Sutherland提出了一种基于编码的判断算法，通过简单的移位、与或逻辑运算就可以判断一条线段处于哪种情况。对于每一个端点$(x,y)$，我们定义一个outcode——$b_0b_1b_2b_3$，视口所处的范围用$x_{min}$、$x_{max}$、$y_{min}$、$y_{max}$表示。每个端点$(x,y)$的outcode的计算方法如下： &emsp;&emsp;$b_0 = 1\\ if \\ y &gt; y_{max},\\ 0\\ otherwiose$ &emsp;&emsp;$b_1 = 1\\ if \\ y &lt; y_{min},\\ 0\\ otherwiose$ &emsp;&emsp;$b_2 = 1\\ if \\ x &gt; x_{min},\\ 0\\ otherwiose$ &emsp;&emsp;$b_3 = 1\\ if \\ x &lt; x_{max},\\ 0\\ otherwiose$ &emsp;&emsp;可以看出outcode将屏幕空间分成了$9$个部分： &emsp;&emsp;观察上面的$9$个区域，对于两个端点outcode1和outcode2，做如下的判断策略，其中的$OR$和$AND$是逻辑按位运算： &emsp;&emsp;若$(outcode1\\ OR\\ outcode2)==0$，那么线段就完全在视口内部； &emsp;&emsp;若$(outcode1\\ AND\\ outcode2)!=0$，那么线段就完全在视口外部； &emsp;&emsp;若$(outcode1\\ AND\\ outcode2)==0$，那么线段就可能部分在视口外部，部分在内部，还需要做进一步的判断（这里我进一步判断用了包围盒，因为比较常见和简单，就不过多描述了）。 &emsp;&emsp;这里我的实现就是只裁剪掉肯定完全在视口外部的线段，若还想裁剪掉部分外视口外部的线段则需要进一步的求交运算。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950bool Pipeline::lineCliping(const VertexOut &amp;from, const VertexOut &amp;to)&#123; // return whether the line is totally outside or not. float vMin = -from.posH.w, vMax = from.posH.w; float x1 = from.posH.x, y1 = from.posH.y; float x2 = to.posH.x, y2 = to.posH.y; int tmp = 0; int outcode1 = 0, outcode2 = 0; // outcode1 calculation. tmp = (y1&gt;vMax)?1:0; tmp &lt;&lt;= 3; outcode1 |= tmp; tmp = (y1&lt;vMin)?1:0; tmp &lt;&lt;= 2; outcode1 |= tmp; tmp = (x1&gt;vMax)?1:0; tmp &lt;&lt;= 1; outcode1 |= tmp; tmp = (x1&lt;vMin)?1:0; outcode1 |= tmp; // outcode2 calculation. tmp = (y2&gt;vMax)?1:0; tmp &lt;&lt;= 3; outcode2 |= tmp; tmp = (y2&lt;vMin)?1:0; tmp &lt;&lt;= 2; outcode2 |= tmp; tmp = (x2&gt;vMax)?1:0; tmp &lt;&lt;= 1; outcode2 |= tmp; tmp = (x2&lt;vMin)?1:0; outcode2 |= tmp; if((outcode1 &amp; outcode2) != 0) return true; // bounding box judge. Vector2D minPoint,maxPoint; minPoint.x = min(from.posH.x, to.posH.x); minPoint.y = min(from.posH.y, to.posH.y); maxPoint.x = max(from.posH.x, to.posH.x); maxPoint.y = max(from.posH.y, to.posH.y); if(minPoint.x &gt; vMax || maxPoint.x &lt; vMin || minPoint.y &gt; vMax || maxPoint.y &lt; vMin) return true; return false;&#125; 三角形裁剪&emsp;&emsp;判断三角形是否完全在外面也不能直接根据三个端点是否完全在视口外部来判断（我看有些软渲染的博主就用了这个错误的策略），因为还要考略以下的特殊情况。 &emsp;&emsp;为此，我直接计算三角形的轴向包围盒，然后这个包围盒判断三角形是否完全是视口外部。更进一步的裁剪是将部分在视口内部的三角形做求交，然后重新分割成完全在视口内部的三角形，这里我没有做进一步的裁剪。 1234567891011121314151617181920212223242526bool Pipeline::triangleCliping(const VertexOut &amp;v1, const VertexOut &amp;v2, const VertexOut &amp;v3)&#123; // true:not clip; // false: clip. float vMin = -v1.posH.w; float vMax = +v1.posH.w; // if the triangle is too far to see it, just return false. if(v1.posH.z &gt; vMax &amp;&amp; v2.posH.z &gt; vMax &amp;&amp; v3.posH.z &gt; vMax) return false; // if the triangle is behind the camera, just return false. if(v1.posH.z &lt; vMin &amp;&amp; v2.posH.z &lt; vMin &amp;&amp; v3.posH.z &lt; vMin) return false; // calculate the bounding box and check if clip or not. Vector2D minPoint,maxPoint; minPoint.x = min(v1.posH.x, min(v2.posH.x, v3.posH.x)); minPoint.y = min(v1.posH.y, min(v2.posH.y, v3.posH.y)); maxPoint.x = max(v1.posH.x, max(v2.posH.x, v3.posH.x)); maxPoint.y = max(v1.posH.y, max(v2.posH.y, v3.posH.y)); if(minPoint.x &gt; vMax || maxPoint.x &lt; vMin || minPoint.y &gt; vMax || maxPoint.y &lt; vMin) return false; return true;&#125; &emsp;&emsp;然后我们把几何裁剪放到渲染管线中，几何裁剪一般是在顶点着色器之后、光栅化之前。这里我把它放到了透视除法和视口变换之前。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364void Pipeline::drawIndex(RenderMode mode)&#123; // renderer pipeline. bool line1 = false, line2 = false, line3 = false; m_mode = mode; if(m_indices.empty()) return; for(unsigned int i = 0;i &lt; m_indices.size();i += 3) &#123; //! assembly to triangle primitive. Vertex p1,p2,p3; &#123; ...... &#125; //! vertex shader stage. VertexOut v1,v2,v3; &#123; ...... &#125; //! geometry cliping. &#123; if(m_mode == RenderMode::wire) &#123; line1 = lineCliping(v1,v2); line2 = lineCliping(v2,v3); line3 = lineCliping(v3,v1); &#125; else if(m_mode == RenderMode::fill &amp;&amp; !triangleCliping(v1,v2,v3)) continue; &#125; //! perspective division. &#123; ...... &#125; //! view port transformation. &#123; ...... &#125; //! rasterization and fragment shader stage. &#123; if(mode == RenderMode::wire) &#123; if(!line1) bresenhamLineRasterization(v1,v2); if(!line2) bresenhamLineRasterization(v2,v3); if(!line3) bresenhamLineRasterization(v3,v1); &#125; else if(mode == RenderMode::fill) &#123; edgeWalkingFillRasterization(v1,v2,v3); &#125; &#125; ...... &#125;&#125; 背面剔除&emsp;&emsp;背面剔除网上的这篇博客已经讲得非常详细了，原理也很简单，我就不过多描述。我们定义顶点逆时针的环绕顺序正面，然后通过三角形的三个顶点计算出法线，将顶点与视线做点乘并判断其符号即可。 123456789101112131415bool Pipeline::backFaceCulling(const Vector4D &amp;v1, const Vector4D &amp;v2, const Vector4D &amp;v3)&#123; // back face culling. if(m_mode == RenderMode::wire) return true; Vector4D tmp1 = v2 - v1; Vector4D tmp2 = v3 - v1; Vector3D edge1(tmp1.x, tmp1.y, tmp1.z); Vector3D edge2(tmp2.x, tmp2.y, tmp2.z); Vector3D viewRay(m_eyePos.x - v1.x, m_eyePos.y - v1.y, m_eyePos.z - v1.z); Vector3D normal = edge1.crossProduct(edge2); return normal.dotProduct(viewRay) &gt; 0;&#125; &emsp;&emsp;然后背面剔除应该放在渲染管线的顶点着色器输出之后，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849void Pipeline::drawIndex(RenderMode mode)&#123; // renderer pipeline. bool line1 = false, line2 = false, line3 = false; m_mode = mode; if(m_indices.empty())return; for(unsigned int i = 0;i &lt; m_indices.size();i += 3) &#123; //! assembly to triangle primitive. Vertex p1,p2,p3; &#123; ...... &#125; //! vertex shader stage. VertexOut v1,v2,v3; &#123; ...... &#125; //! back face culling. &#123; if(!backFaceCulling(v1.posTrans, v2.posTrans, v3.posTrans)) continue; &#125; //! geometry cliping. &#123; ...... &#125; //! perspective division. &#123; ...... &#125; //! view port transformation. &#123; ...... &#125; //! rasterization and fragment shader stage. &#123; ...... &#125; &#125;&#125; 透视纹理映射、采样&emsp;&emsp;纹理映射是丰富三维物体细节的一个非常重要的方法，简单、廉价、快速，只需计算好的纹理坐标、纹理图片即可实现物体的多姿多彩。通常纹理图片的制作（除了过程式纹理的生成）由设计师完成，无需我们关心。而纹理坐标的计算则需要非常注意，送入渲染管线的纹理坐标只是逐顶点的纹理坐标，在光栅化阶段我们还要将纹理坐标做插值操作，最后根据插值后得到的纹理坐标对纹理图片采样获取片元的像素值。 透视纹理映射&emsp;&emsp;在光栅化阶段，我们是根据屏幕空间的$x$值和$y$值做线性插值操作获取片元的位置，而片元的纹理坐标如果也这么获得的话（这种方法叫做仿射纹理映射），将会导致严重的纹理扭曲。这是因为仿射纹理映射是基于这样的一个假设：物体空间的纹理坐标与屏幕空间的顶点坐标呈线性管线。 &emsp;&emsp;我们知道纹理坐标是定义在物体的顶点上面的，当我们根据屏幕空间的顶点坐标插值时，就默认了纹理坐标的变化与屏幕空间顶点坐标的变化是呈线性、均匀的关系的。但是问题在于：默认的屏幕空间上的线性关系，还原到世界空间中，就不是那么回事了，如下图所示。这张图是相机空间的一张俯视图。我们把一个多边形通过透视投影的方式变换到了投影平面上，图中红色的是世界空间中的多边形，蓝色的是变换到投影平面之后的多边形。可以看到，在投影平面上的蓝色线段被表示成若干个相等的单位步长线段。与此同时，投影面上单位步长的线段所对应的投影之前的红色线段的长度却不是相等的，从左到右所对应的长度依次递增。我们的纹理坐标是定义在红色的多边形上的，因此纹理坐标的增量应该是和红色线段的步长对应的。我们的线性插值却把纹理坐标增量根据蓝色线段的步长平均分配了。 &emsp;&emsp;这就导致了仿射纹理映射的错误的结果，如下图所示，仿射纹理映射产生了严重的扭曲。 &emsp;&emsp;而如果你不信，大可以试一试，然后你就会得到和我下面这张图一样奇怪的结果。 &emsp;&emsp;那么如何进行矫正了？网上的这篇博客已经非常详细地说明了相关的矫正方法，核心思想就是想办法让纹理坐标变得与屏幕空间的坐标线性相关，这一点可以看成纹理坐标的透视投影（与世界空间的顶点坐标投影到屏幕空间，从而通过插值获得其他的屏幕空间坐标进行光栅化有异曲同工之妙）。 &emsp;&emsp;纹理透视投影的详细过程请看这篇博客，其中借助的关系就是纹理坐标与世界空间顶点坐标是相关的（我们定义纹理坐标就是逐个顶点定义的），然后世界空间顶点坐标（为了便于讨论，这里世界空间就是视图空间）通过投影矩阵变成屏幕空间顶点坐标。在世界空间中，顶点的$x$和$y$值与$z$值呈线性关系（因为我们定义基本图元是三角形，在三角形平面上，必然是线性的，否则就是非线性的曲面了），即存在$A$和$B$有： x_e = Az_e+B\\\\ y_e = Az_e+B \\tag {2}&emsp;&emsp;$(x_e,y_e,z_e)$是视图空间的顶点坐标，即$(x’,y’)$是投影到近平面的顶点坐标。根据透视投影矩阵可知（其实就是相似三角形），$(x’,y’)$与视图空间的顶点坐标关系如下： \\begin{cases} x'=-N\\frac {x_e}{z_e}\\ \\to x_e= -\\frac{x'z_e}{N} \\\\ y'=-N\\frac {y_e}{z_e}\\ \\to y_e= -\\frac{y'z_e}{N} \\end{cases} \\tag {3}&emsp;&emsp;将公式$(3)$带入公式$(2)$，则有： \\begin{cases} x'=-N\\frac{B}{z_e}-AN\\\\ y'=-N\\frac{B}{z_e}-AN \\end{cases} \\tag {4}&emsp;&emsp;其中的$A$、$B$、$N$都是常量，把$\\frac 1{z_e}$看成一个整体，则通过透视投影矩阵的变换之后$x’$、$y’$均与$\\frac{1}{z_e}$成线性关系，这也就是透视投影的效果是近大远小的根本原因。然后注意到在三维空间中，纹理坐标$(s,t)$和$(x_e,y_e)$成线性关系。即有（这里只是定性分析，$A$和$B$具体多少我们不用关心）： \\begin{cases} x_e=As+B\\\\ x_e=At+B\\\\ y_e=As+B\\\\ y_e=At+B \\end{cases} \\tag {5}&emsp;&emsp;把公式$(5)$带入$(3)$则有（以公式$(5)$的第一个为例，其他类似）： As+B=-\\frac{x'z_e}{N}\\ \\to\\ A\\frac{s}{z_e}+B\\frac{1}{z_e}=-\\frac{x'}{N} \\tag {6}&emsp;&emsp;公式$(6)$彻底说明了纹理坐标与屏幕空间的顶点坐标的关系！$s$和$x’$并不是简单的线性关系，因为还出现了$\\frac{1}{z_e}$这个项，如果$\\frac{1}{z_e}$具体值已知，那么$\\frac{s}{z_e}$就与 $x’$成线性关系！那么我们在线性插值之前给纹理坐标$s$乘上一个$\\frac{1}{z_e}$，就可以根据屏幕空间的顶点坐标做线性插值了，然后对插值得到的纹理坐标$s’$乘上$z_e$就能还原出正确的纹理坐标！！！！ &emsp;&emsp;说了这么多都是在捋清函数关系，实现其实很简单的，上面已经说的很清楚了。我们在$VertexOut$中定义的变量$oneDivZ$就用于的透射投影映射的。除开纹理坐标，其他的世界空间坐标、顶点颜色、法线都是定义在世界空间的坐标顶点上的，为了得到正确的插值，都需要做与纹理坐标一样的处理。乘上$\\frac{1}{z_e}$这一步我放在了顶点着色器的最后一步，只要放在插值之前都行。 1234567891011VertexOut SimpleShader::vertexShader(const Vertex &amp;in)&#123; ..... // oneDivZ to correct mapping. result.oneDivZ = 1.0 / result.posH.w; result.posTrans *= result.oneDivZ; result.texcoord *= result.oneDivZ; result.color *= result.oneDivZ; return result;&#125; &emsp;&emsp;然后再光栅化插值之后各自乘上相应的倒数即可恢复出正确的插值结果。 123456789101112131415161718192021222324252627void Pipeline::scanLinePerRow(const VertexOut &amp;left, const VertexOut &amp;right)&#123; // scan the line from left to right. VertexOut current; int length = right.posH.x - left.posH.x + 1; for(int i = 0;i &lt;= length;++i) &#123; // linear interpolation double weight = static_cast&lt;double&gt;(i)/length; current = lerp(left, right, weight); current.posH.x = left.posH.x + i; current.posH.y = left.posH.y; // depth testing. ...... // restore. double w = 1.0/current.oneDivZ; current.posTrans *= w; current.color *= w; current.texcoord *= w; // fragment shader m_backBuffer-&gt;drawPixel(current.posH.x, current.posH.y, m_shader-&gt;fragmentShader(current)); &#125;&#125; 双线性纹理采样&emsp;&emsp;定义的纹理坐标都是$[0.0f,1.0f]$的浮点数，为了采样纹理我们需要把它乘上纹理的宽高转成整数的下标取访问纹理的像素矩阵。乘上纹理的宽高之后我们得到的依然应该是一个浮点数，为了获取像素下标，一个简单的方法就是向下取整（这种采样方法对应于OpenGL的GL_NEAREST纹理过滤方法）。如下所示： 12345678910double trueU = texcoord.x * (m_width - 1);double trueV = texcoord.y * (m_height - 1);x = static_cast&lt;unsigned int&gt;(trueU);y = static_cast&lt;unsigned int&gt;(trueV);int index[0] = (x * m_width + y) * m_channel;Vector3D texels;// INV_SCALE is 1.0/255texels.x = static_cast&lt;float&gt;(m_pixelBuffer[index + 0]) * INV_SCALE;texels.y = static_cast&lt;float&gt;(m_pixelBuffer[index + 1]) * INV_SCALE;texels.z = static_cast&lt;float&gt;(m_pixelBuffer[index + 2]) * INV_SCALE; &emsp;&emsp;问题就出在这里，这样直接抛弃小数点以后的值导致采样出的相邻纹理并不连续，那么用float采样行吗？答案是：不行！这边实现的采样函数是从数组取值，纹理坐标转为数组下标，数组下标不能用float只能用int，那么就没办法了吗？并不是，可以对周围纹理进行采样然后按照各自比例进行混合，这样能够提高显示效果。混合的方法就是双线性插值。所谓双线性插值，就是先后线性插值一次，共两次。即横向线性插值一次，然后根据前面一次的插值结果竖向插值一次，二维纹理是有两个维度，所以做双线性插值。 &emsp;&emsp;除了采样之外，还有一个纹理坐标溢出的问题。纹理坐标超过的$[0,1]$通常由两种处理方式，一种是$clamp$，超过$[0,1]$的地方的像素都获取边上的像素，这样效果就是拉伸。一种是$repeat$，故名思议，即重复平铺。这里我实现的是重复平铺，在计算真正的纹理下标之前做相应的判断和处理即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108class Texture2D&#123;private: int m_width; int m_height; int m_channel; unsigned char *m_pixelBuffer;public: Texture2D():m_width(0), m_height(0), m_channel(0), m_pixelBuffer(nullptr)&#123;&#125; ~Texture2D(); bool loadImage(const std::string &amp;path); Vector4D sample(const Vector2D &amp;texcoord) const;&#125;;bool Texture2D::loadImage(const std::string &amp;path)&#123; if(m_pixelBuffer)delete m_pixelBuffer; m_pixelBuffer = nullptr; m_pixelBuffer = stbi_load(path.c_str(), &amp;m_width, &amp;m_height, &amp;m_channel, 0); if(m_pixelBuffer == nullptr) &#123; qDebug() &lt;&lt; \"Failed to load image-&gt;\" &lt;&lt; QString::fromStdString(path); &#125; return m_pixelBuffer != nullptr;&#125;Vector4D Texture2D::sample(const Vector2D &amp;texcoord) const&#123; // just for rgb and rgba format. Vector4D result(0.0,0.0,0.0,1.0); if(m_pixelBuffer == nullptr) return result; unsigned int x = 0, y = 0; // for bilinear interpolation. double factorU = 0, factorV = 0; // calculate the corresponding coordinate. if(texcoord.x &gt;= 0.0f &amp;&amp; texcoord.x &lt;= 1.0f &amp;&amp; texcoord.y &gt;= 0.0f &amp;&amp; texcoord.y &lt;= 1.0f) &#123; double trueU = texcoord.x * (m_width - 1); double trueV = texcoord.y * (m_height - 1); x = static_cast&lt;unsigned int&gt;(trueU); y = static_cast&lt;unsigned int&gt;(trueV); factorU = trueU - x; factorV = trueV - y; &#125; else &#123; // repeating way. float u = texcoord.x,v = texcoord.y; if(texcoord.x &gt; 1.0f) u = texcoord.x - static_cast&lt;int&gt;(texcoord.x); else if(texcoord.x &lt; 0.0f) u = 1.0f - (static_cast&lt;int&gt;(texcoord.x) - texcoord.x); if(texcoord.y &gt; 1.0f) v = texcoord.y - static_cast&lt;int&gt;(texcoord.y); else if(texcoord.y &lt; 0.0f) v = 1.0f - (static_cast&lt;int&gt;(texcoord.y) - texcoord.y); double trueU = u * (m_width - 1); double trueV = v * (m_height - 1); x = static_cast&lt;unsigned int&gt;(trueU); y = static_cast&lt;unsigned int&gt;(trueV); factorU = trueU - x; factorV = trueV - y; &#125; // texel fetching. Vector3D texels[4]; int index[4]; index[0] = (x * m_width + y) * m_channel; index[1] = (x * m_width + y + 1) * m_channel; index[2] = ((x + 1) * m_width + y + 1) * m_channel; index[3] = ((x + 1) * m_width + y) * m_channel; // left bottom texels[0].x = static_cast&lt;float&gt;(m_pixelBuffer[index[0] + 0]) * INV_SCALE; texels[0].y = static_cast&lt;float&gt;(m_pixelBuffer[index[0] + 1]) * INV_SCALE; texels[0].z = static_cast&lt;float&gt;(m_pixelBuffer[index[0] + 2]) * INV_SCALE; //return texels[0]; // left top texels[1].x = static_cast&lt;float&gt;(m_pixelBuffer[index[1] + 0]) * INV_SCALE; texels[1].y = static_cast&lt;float&gt;(m_pixelBuffer[index[1] + 1]) * INV_SCALE; texels[1].z = static_cast&lt;float&gt;(m_pixelBuffer[index[1] + 2]) * INV_SCALE; // right top texels[2].x = static_cast&lt;float&gt;(m_pixelBuffer[index[2] + 0]) * INV_SCALE; texels[2].y = static_cast&lt;float&gt;(m_pixelBuffer[index[2] + 1]) * INV_SCALE; texels[2].z = static_cast&lt;float&gt;(m_pixelBuffer[index[2] + 2]) * INV_SCALE; // right bottom texels[3].x = static_cast&lt;float&gt;(m_pixelBuffer[index[3] + 0]) * INV_SCALE; texels[3].y = static_cast&lt;float&gt;(m_pixelBuffer[index[3] + 1]) * INV_SCALE; texels[3].z = static_cast&lt;float&gt;(m_pixelBuffer[index[3] + 2]) * INV_SCALE; // bilinear interpolation. // horizational texels[0] = texels[0] * (1.0 - factorU) + texels[3] * factorU; texels[1] = texels[1] * (1.0 - factorU) + texels[2] * factorU; //vertical result = texels[0] * (1.0 - factorV) + texels[1] *factorV; return result;&#125; &emsp;&emsp;加载图片我的用的stb_image，一个简单使用的头文件，因为加载图片不是我们的重点，所以就不造这方面的轮子了。 程序结果&emsp;&emsp;目前的帧率还不错hhh。 参考资料$[1]$ https://learnopengl.com/Advanced-OpenGL/Depth-testing $[2]$ https://www.cnblogs.com/pbblog/p/3484193.html $[3]$ https://learnopengl.com/Getting-started/Coordinate-Systems $[4]$ http://www.songho.ca/opengl/gl_projectionmatrix.html $[5]$ https://blog.csdn.net/popy007/article/details/5570803 $[6]$ https://learnopengl-cn.github.io/01%20Getting%20started/06%20Textures/","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"http://yoursite.com/categories/Computer-Graphics/"},{"name":"Soft Renderer","slug":"Soft-Renderer","permalink":"http://yoursite.com/categories/Soft-Renderer/"}],"tags":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"http://yoursite.com/tags/Computer-Graphics/"},{"name":"Soft Renderer","slug":"Soft-Renderer","permalink":"http://yoursite.com/tags/Soft-Renderer/"},{"name":"3D pipeline","slug":"3D-pipeline","permalink":"http://yoursite.com/tags/3D-pipeline/"}]},{"title":"软渲染器Soft Renderer：光栅化篇","slug":"SoftRenderer-Rasterization","date":"2019-05-01T02:37:54.047Z","updated":"2019-05-01T01:56:05.930Z","comments":true,"path":"2019/05/01/SoftRenderer-Rasterization/","link":"","permalink":"http://yoursite.com/2019/05/01/SoftRenderer-Rasterization/","excerpt":"本章开始构建基于Qt平台软渲染器的初步框架，当然Qt相关的内容并不是软渲染器的重点，我只是借助Qt平台将渲染出来的像素矩阵用Qt的控件显示出来。光栅化是当今图形学渲染的一种方式，与之对应的是光线追踪渲染方式，本章我根据自己的理解着重讲述线框光栅化的Bresenham画线算法以及三角形填充光栅化的Edge-Walking算法。注意：初学者慎入。本篇相关的完整代码请看这里。","text":"本章开始构建基于Qt平台软渲染器的初步框架，当然Qt相关的内容并不是软渲染器的重点，我只是借助Qt平台将渲染出来的像素矩阵用Qt的控件显示出来。光栅化是当今图形学渲染的一种方式，与之对应的是光线追踪渲染方式，本章我根据自己的理解着重讲述线框光栅化的Bresenham画线算法以及三角形填充光栅化的Edge-Walking算法。注意：初学者慎入。本篇相关的完整代码请看这里。 渲染管线框架 光栅化算法 渲染管线框架&emsp;&emsp;渲染管线的搭建主要包含像素显示、网格数据封装、渲染循环、帧率fps计算、帧缓冲、着色器、渲染逻辑、光栅化等等，其中光栅化作为重点对象抽出来放在后面。当然我们不会一下子就完成渲染管线的基本功能，我们现在是要搭建一个框架，大部分的内容不用写入或者仅仅是做简单的处理，这样后面完善软渲染器的时候只需在相应的位置填写相应的代码逻辑即可。本章目标就是搭建一个渲染管线，用光栅化算法画三角形。当然，如果仅仅是画一个三角形，当然不用这么麻烦，但是我的目标是实现三维的软渲染器，深入理解三维渲染的整个流程，得从基础一步一步慢慢来。 像素显示的画布&emsp;&emsp;渲染器最终渲染出来的是一个像素矩阵，我们要把这个像素矩阵显示出来。显示的方法有很多，因人而异，这里我采用自己最熟悉的$Qt$来实现。显示的窗口继承一个普通的$QWidget$父类，然后我们通过重写它的$paintEvent$函数，将渲染出来的像素画到$QWidget$上。但是采用$QPainter$直接画上去的方式效率非常低，我通过查询资料得知，若想要快速地绘制给定的像素矩阵，可以利用$QImage$来实现。话不多说，上代码： 123456789101112131415class Window : public QWidget&#123; Q_OBJECTpublic: explicit Window(QWidget *parent = nullptr); ~Window();private: void paintEvent(QPaintEvent *) override;private: Ui::Window *ui; QImage *canvas;&#125;; &emsp;&emsp;接收到一帧的像素之后，在重绘事件里面利用$QImage$绘制给定的像素数组（记得调用$update$触发重绘事件）。由于篇幅原因，我不会讲太多细节方面的东西，代码也不会全部放出来，那样没意义。想看完整源代码的朋友直接去本人的github上看。 12345678910111213141516void Window::receiveFrame(unsigned char *image)&#123; if(canvas) delete canvas; canvas = new QImage(image, width(), height(), QImage::Format_RGBA8888); update();&#125;void Window::paintEvent(QPaintEvent *event)&#123; if(canvas) &#123; QPainter painter(this); painter.drawImage(0, 0, *canvas); &#125; QWidget::paintEvent(event);&#125; 帧缓冲类&emsp;&emsp;帧缓冲通常包含基本的颜色缓冲附件、深度缓冲附件等，这里我们暂且只实现颜色缓冲附件（四通道，格式为$RGBA$，各占一个字节），深度缓冲附件后面再加上。渲染管线最终的渲染结果是写入帧缓冲的，我们采用一个一维的单字节数组作为帧缓冲的颜色缓冲。帧缓冲的最基本的功能就是清楚缓冲区、写入像素： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class FrameBuffer&#123;private: int m_width, m_height, m_channel; std::vector&lt;unsigned char&gt; m_colorBuffer;public: FrameBuffer(int width, int height); ~FrameBuffer() = default; int getWidth()&#123;return m_width;&#125; int getHeight()&#123;return m_height;&#125; unsigned char *getColorBuffer() &#123;return m_colorBuffer.data();&#125; void clearColorBuffer(const Vector4D &amp;color); void drawPixel(unsigned int x, unsigned int y, const Vector4D &amp;color);&#125;;FrameBuffer::FrameBuffer(int width, int height) :m_channel(4), m_width(width), m_height(height)&#123; m_colorBuffer.resize(m_width*m_height*m_channel, 255);&#125;void FrameBuffer::clearColorBuffer(const Vector4D &amp;color)&#123; // fill the color buffer. unsigned char red = static_cast&lt;unsigned char&gt;(255*color.x); unsigned char green = static_cast&lt;unsigned char&gt;(255*color.y); unsigned char blue = static_cast&lt;unsigned char&gt;(255*color.z); unsigned char alpha = static_cast&lt;unsigned char&gt;(255*color.w); for(int row = 0;row &lt; m_height;++ row) &#123; for(int col = 0;col &lt; m_width;++ col) &#123; m_colorBuffer[row*m_width*m_channel+col*m_channel + 0] = red; m_colorBuffer[row*m_width*m_channel+col*m_channel + 1] = green; m_colorBuffer[row*m_width*m_channel+col*m_channel + 2] = blue; m_colorBuffer[row*m_width*m_channel+col*m_channel + 3] = alpha; &#125; &#125;&#125;void FrameBuffer::drawPixel(unsigned int x, unsigned int y, const Vector4D &amp;color)&#123; if(x &lt; 0 || x &gt;= m_width || y &lt; 0 || y &gt;= m_height) return; unsigned char red = static_cast&lt;unsigned char&gt;(255*color.x); unsigned char green = static_cast&lt;unsigned char&gt;(255*color.y); unsigned char blue = static_cast&lt;unsigned char&gt;(255*color.z); unsigned char alpha = static_cast&lt;unsigned char&gt;(255*color.w); unsigned int index = y*m_width*m_channel + x*m_channel; m_colorBuffer[index + 0] = red; m_colorBuffer[index + 1] = green; m_colorBuffer[index + 2] = blue; m_colorBuffer[index + 3] = alpha;&#125; 网格顶点数据&emsp;&emsp;三维的渲染程序中的顶点数据通常包含顶点位置、顶点颜色、纹理坐标、顶点法线，然后在此基础上利用一组给定顺序的顶点数据表示一个网格，渲染时网格的数据将被送入管线进行处理。为此，有必要对顶点数据做一定的封装。 1234567891011121314class Vertex&#123;public: Vector4D position; Vector4D color; Vector2D texcoord; Vector3D normal; Vertex() = default; Vertex(Vector4D _pos, Vector4D _color, Vector2D _tex, Vector3D _normal) :position(_pos),color(_color),texcoord(_tex),normal(_normal) &#123;&#125; Vertex(const Vertex &amp;rhs) :position(rhs.position),color(rhs.color),texcoord(rhs.texcoord),normal(rhs.normal)&#123;&#125;&#125;; &emsp;&emsp;顶点数据经过顶点着色器的处理之后，会被送到下一个渲染管线的阶段处理。顶点着色器的顶点数据输出与输入有些差异，为此我们也定义一个类表示为顶点着色器的输出，这对于构建渲染管线尤为重要。 12345678910111213141516171819class VertexOut&#123;public: Vector4D posTrans; //世界变换后的坐标 Vector4D posH; //投影变换后的坐标 Vector2D texcoord; //纹理坐标 Vector3D normal; //法线 Vector4D color; //颜色 double oneDivZ; //1/z用于深度测试 VertexOut() = default; VertexOut(Vector4D _posT, Vector4D _posH, Vector2D _tex, Vector3D _normal, Vector4D _color, double _oneDivZ) :posTrans(_posT),posH(_posH),texcoord(_tex), normal(_normal),color(_color),oneDivZ(_oneDivZ) &#123;&#125; VertexOut(const VertexOut&amp; rhs) :posTrans(rhs.posTrans), posH(rhs.posH), texcoord(rhs.texcoord), normal(rhs.normal), color(rhs.color), oneDivZ(rhs.oneDivZ) &#123;&#125;&#125;; &emsp;&emsp;然后就是关于网格的表示，为了节省空间（特别是对于很大的模型），我们直接采用索引来组织网格。若想详细了解OpenGL的顶点索引概念请看这里。一个网格有两个数组，分别是$Vertex$数组和$Index$数组。下面的代码中，有一个$asTriangle$方法，这是一个三角形网格，调用这个方法之后网格存储的就是一个三角形，用于后面的光栅化调试，光栅化的基本单元就是三角形。通常情况，所有的网格模型都可以用一定数量的三角形构成，因而我们实现的软渲染器的基本图元就是三角形。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Mesh&#123;public: std::vector&lt;Vertex&gt; vertices; std::vector&lt;unsigned int&gt; indices; Mesh() = default; ~Mesh() = default; Mesh(const Mesh&amp; mesh) :vertices(mesh.vertices), indices(mesh.indices)&#123;&#125; Mesh&amp; operator=(const Mesh&amp; mesh) &#123; if (&amp;mesh == this) return *this; vertices = mesh.vertices; indices = mesh.indices; return *this; &#125; void setVertices(Vertex* _vs, int count) &#123; vertices.resize(count); new(&amp;vertices[0])std::vector&lt;Vertex&gt;(_vs, _vs + count); &#125; void setIndices(int* _es, int count) &#123; indices.resize(count); new(&amp;indices)std::vector&lt;unsigned int&gt;(_es, _es + count); &#125; void asBox(double width, double height, double depth); void asTriangle(const Vector3D p1, const Vector3D p2, const Vector3D p3);&#125;;void Mesh::asTriangle(Vector3D p1, Vector3D p2, Vector3D p3)&#123; vertices.resize(3); indices.resize(3); vertices[0].position = p1; vertices[0].normal = Vector3D(0.f, 0.f, 1.f); vertices[0].color = Vector4D(1.f, 0.f, 0.f, 1.f); vertices[0].texcoord = Vector2D(0.f, 0.f); vertices[1].position = p2; vertices[1].normal = Vector3D(0.f, 0.f, 1.f); vertices[1].color = Vector4D(0.f, 1.f, 0.f, 1.f); vertices[1].texcoord = Vector2D(1.f, 0.f); vertices[2].position = p3; vertices[2].normal = Vector3D(0.f, 0.f, 1.f); vertices[2].color = Vector4D(0.f, 0.f, 1.f, 1.f); vertices[2].texcoord = Vector2D(0.5f, 1.f); indices[0] = 0; indices[1] = 1; indices[2] = 2;&#125; 简单的着色器&emsp;&emsp;着色器方面时软渲染中较为高级的内容，目前我们只是搭建一个框架，因而着色器不需要什么复杂的操作，只需简单地传递数据就行了。博主实现的软渲染器只包含必不可少的顶点着色器和片元着色器，目前的顶点着色器将顶点原封不动地输出，片元着色器也是如此，这样我们后面要实现光照效果的时候直接在着色器里写上就行了。为了更加有条理，我们设计一个着色器的虚类，这样实现不同效果的着色器时我们直接继承这个虚类即可。 123456789101112class BaseShader&#123;public: BaseShader() = default; virtual ~BaseShader() = default; virtual VertexOut vertexShader(const Vertex &amp;in) = 0; virtual Vector4D fragmentShader(const VertexOut &amp;in) = 0; virtual void setModelMatrix(const Matrix4x4 &amp;world) = 0; virtual void setViewMatrix(const Matrix4x4 &amp;view) = 0; virtual void setProjectMatrix(const Matrix4x4 &amp;project) = 0;&#125;; 12345678910111213141516171819202122232425262728293031323334353637383940414243class SimpleShader : public BaseShader&#123;public: SimpleShader() = default; virtual ~SimpleShader() = default; virtual VertexOut vertexShader(const Vertex &amp;in); virtual Vector4D fragmentShader(const VertexOut &amp;in); virtual void setModelMatrix(const Matrix4x4 &amp;world); virtual void setViewMatrix(const Matrix4x4 &amp;view); virtual void setProjectMatrix(const Matrix4x4 &amp;project);&#125;;VertexOut SimpleShader::vertexShader(const Vertex &amp;in)&#123; VertexOut result; result.posTrans = in.position; result.posH = in.position; result.color = in.color; result.normal = in.normal; result.oneDivZ = 1.0; result.texcoord = in.texcoord; return result;&#125;Vector4D SimpleShader::fragmentShader(const VertexOut &amp;in)&#123; Vector4D litColor; litColor = in.color; return litColor;&#125;void SimpleShader::setModelMatrix(const Matrix4x4 &amp;world)&#123;&#125;void SimpleShader::setViewMatrix(const Matrix4x4 &amp;view)&#123;&#125;void SimpleShader::setProjectMatrix(const Matrix4x4 &amp;project)&#123;&#125; &emsp;&emsp;可以看到$SimpleShader$仅仅是将顶点数据直接输出，不进行任何处理。 搭建基本的渲染管线&emsp;&emsp;目前我们已经有了一些渲染管线的基本组件，现在就需要把这些组件串起来。首先是渲染循环的问题，$Qt$有它自己的事件循环，而且主线程的事件循环要尽量避免大量的运算（否则UI控件会陷入未响应），因此将渲染循环放到子线程里是一个不错的渲染，这样也可以避免我们的软渲染逻辑与$Qt$的接口耦合得太高。 渲染线程&emsp;&emsp;$Qt$提供了$QThread$类构建线程，我采用的方式为：渲染循环类继承$QObject$，然后调用$moveToThread$番方法挂到子线程上运行，最后将线程的启动信号与$loop$渲染循环关联即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class RenderLoop : public QObject&#123; Q_OBJECTpublic: explicit RenderLoop(int w, int h, QObject *parent = nullptr); ~RenderLoop(); void stopIt() &#123;stoped = true;&#125; void setFpsZero()&#123;fps = 0;&#125; int getFps()&#123;return fps;&#125;signals: void frameOut(unsigned char *image);public slots: void loop();private: bool stoped; int fps; int width, height, channel;&#125;;RenderLoop::RenderLoop(int w, int h, QObject *parent) : QObject(parent), width(w), height(h), channel(4)&#123; fps = 0; stoped = false;&#125;RenderLoop::~RenderLoop()&#123;&#125;void RenderLoop::loop()&#123; // pipeline initialization ...... // fps counting. fps = 0; while(!stoped) &#123; // render logic ...... ++ fps; &#125;&#125; &emsp;&emsp;然后在主窗口中创建$RenderLoop$对象，挂到$QThread$上启动。此外还有一点要注意的是在子线程中最好不用使用$QTimer$类，因此我在主窗口中创建$QTimer$类，设定为每秒触发，触发时主线程读取子线程的$fps$，这样就达到了显示帧率的目的了。 12345678910111213141516171819202122232425262728293031在Window类声明处：private: QTimer *timer; QThread *loopThread; RenderLoop *loop;在Window类构造函数处： loop = new RenderLoop(width(), height(), nullptr); loopThread = new QThread(this); // fps counting. timer = new QTimer(); connect(timer,&amp;QTimer::timeout,this,&amp;Window::fpsTimeOut); // render thread. loop-&gt;moveToThread(loopThread); connect(loopThread,&amp;QThread::finished,loop, &amp;RenderLoop::deleteLater); connect(loopThread,&amp;QThread::started,loop,&amp;RenderLoop::loop); connect(loop,&amp;RenderLoop::frameOut,this,&amp;Window::receiveFrame); // begin the thread. loopThread-&gt;start(); timer-&gt;start(1000);Window的其他函数：void Window::fpsTimeOut()&#123; int fps = loop-&gt;getFps(); loop-&gt;setFpsZero(); this-&gt;setWindowTitle(QString(\" fps: %1\").arg(fps));&#125; 渲染流程&emsp;&emsp;回顾一下$OpenGL$的渲染流程（这里只考虑一般的情况，即不包含几何着色器、细分着色器等），首先外部处理网格，将网格顶点数据和网格顶点索引送入渲染管线，设置基本图元（如三角形）、渲染方式（如线框模式）。渲染管线的第一阶段为顶点着色器阶段（在这之前还有个缓冲清理阶段），顶点着色器对网格数据逐顶点处理（包含坐标空间变换、投影变换等等），随之输出。然后渲染管线对输出的顶点数据进行裁剪，送入光栅化部件，计算几何图元覆盖的像素点，其中进行了大量的线性插值操作。接着片元着色器获取光栅化后的像素，对每个像素做颜色计算等，然后输出颜色数据、深度数据，最后根据这些缓冲数据做深度测试。 &emsp;&emsp;所以一个最基本的渲染管线应该有如下几个步骤： &emsp;&emsp;初始化（如缓冲区创建）$\\to$输入顶点缓冲、索引缓冲$\\to$清除缓冲区$\\to$设置着色器、渲染方式$\\to$绘制$\\to$交换双缓冲$\\to$输出。根据这些步骤，创建$Pipeline$类如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192class Pipeline&#123;private: int m_width, m_height; // width and height of viewport. BaseShader *m_shader; // shaders including vertex shader and fragment shader. FrameBuffer *m_frontBuffer; FrameBuffer *m_backBuffer; Matrix4x4 viewPortMatrix; // viewport transformation matrix. std::vector&lt;Vertex&gt; m_vertices; // vertex buffer. std::vector&lt;unsigned int&gt; m_indices;// index buffer.public: Pipeline(int width, int height); ~Pipeline(); void initialize(); void clearBuffer(const Vector4D &amp;color, bool depth = false); void setVertexBuffer(const std::vector&lt;Vertex&gt; &amp;vertices)&#123;m_vertices = vertices;&#125; void setIndexBuffer(const std::vector&lt;unsigned int&gt; &amp;indices)&#123;m_indices = indices;&#125; void setShaderMode(ShadingMode mode); void drawIndex(RenderMode mode); void swapBuffer(); unsigned char *output()&#123;return m_frontBuffer-&gt;getColorBuffer();&#125;&#125;;Pipeline::Pipeline(int width, int height) :m_width(width),m_height(height) ,m_shader(nullptr),m_frontBuffer(nullptr) ,m_backBuffer(nullptr)&#123;&#125;Pipeline::~Pipeline()&#123; if(m_shader)delete m_shader; if(m_frontBuffer)delete m_frontBuffer; if(m_backBuffer)delete m_backBuffer; m_shader = nullptr; m_frontBuffer = nullptr; m_backBuffer = nullptr;&#125;void Pipeline::initialize()&#123; if(m_frontBuffer) delete m_frontBuffer; if(m_backBuffer) delete m_backBuffer; if(m_shader) delete m_shader; viewPortMatrix.setViewPort(0,0,m_width,m_height); m_frontBuffer = new FrameBuffer(m_width, m_height); m_backBuffer = new FrameBuffer(m_width, m_height); m_shader = new SimpleShader();&#125;void Pipeline::drawIndex(RenderMode mode)&#123; 输入顶点着色器; 光栅化; 输入片元着色器; 写入缓冲区;&#125;void Pipeline::clearBuffer(const Vector4D &amp;color, bool depth)&#123; (void)depth; m_backBuffer-&gt;clearColorBuffer(color);&#125;void Pipeline::setShaderMode(ShadingMode mode)&#123; if(m_shader)delete m_shader; if(mode == ShadingMode::simple) m_shader = new SimpleShader(); else if(mode == ShadingMode::phong) ;&#125;void Pipeline::swapBuffer()&#123; FrameBuffer *tmp = m_frontBuffer; m_frontBuffer = m_backBuffer; m_backBuffer = tmp;&#125; &emsp;&emsp;注意到我创建了帧缓冲，分别是$m_frontBuffer$和$m_backBuffer$，前者存储着当前显示的像素，后者缓冲区用于写入像素。这就是著名的双缓冲原理，可以避免画面的闪烁、撕裂等现象。除此之外，还有一个值得特别说明的就是视口变换矩阵$viewPortMatrix$，这个一般很少见到，因为被内嵌在了渲染管线里面了。经过投影变换、透视除法操作之后，顶点数据都在标准化设备空间中，即$x$轴、$y$轴、$z$轴取值范围为$[-1,1]$。但是屏幕的像素坐标范围并非如此，通常屏幕的$x$轴坐标范围为$[0,width]$，$y$轴坐标范围为$[0,height]$，屏幕像素坐标原点在左上角，$x$轴正向朝右，$y$轴正向朝下，所以我们还要把标准化设备坐标顶点数据变换到屏幕的坐标范围中，这就是视口变换（$z$轴一般保持不变）。视口变换矩阵的构造并没有难度，因为这仅仅是简单的线性映射，因此不再赘述。视口变换矩阵如下所示： viewPortMatrix= \\left[ \\begin{matrix} \\frac{w}{2}&0&0&s_x+\\frac{w}{2}\\\\ 0&-\\frac{h}{2}&0&s_y+\\frac{h}{2}\\\\ 0&0&1&0\\\\ 0&0&0&1 \\end{matrix} \\right] \\tag {1}&emsp;&emsp;其中$(s_x,s_y)$是视口左上角的坐标，$(w,h)$为屏幕的宽度和高度。 12345678void Matrix4x4::setViewPort(int left, int top, int width, int height)&#123; loadIdentity(); entries[0] = static_cast&lt;float&gt;(width)/2.0f; entries[5] = -static_cast&lt;float&gt;(height)/2.0f; entries[12] = static_cast&lt;float&gt;(left)+static_cast&lt;float&gt;(width)/2.0f; entries[13] = static_cast&lt;float&gt;(top)+static_cast&lt;float&gt;(height)/2.0f;&#125; &emsp;&emsp;$Pipeline$还有个非常重要的函数$drawIndex$，它是渲染管线的核心部分，涉及到了图元装配、顶点着色器调度、光栅化、片元着色器调度、写入帧缓冲这几个重要的步骤。我们实现的软渲染器几何图元默认为三角形，所以图元装配就是每三个顶点装成一个图元。 123456789101112131415161718192021222324252627282930313233343536373839void Pipeline::drawIndex(RenderMode mode)&#123; if(m_indices.empty())return; for(unsigned int i = 0;i &lt; m_indices.size()/3;++ i) &#123; //! vertices assembly to triangle primitive Vertex p1,p2,p3; &#123; p1 = m_vertices[3*i+0]; p2 = m_vertices[3*i+1]; p3 = m_vertices[3*i+2]; &#125; //! vertex shader stage. VertexOut v1,v2,v3; &#123; v1 = m_shader-&gt;vertexShader(p1); v2 = m_shader-&gt;vertexShader(p2); v3 = m_shader-&gt;vertexShader(p3); &#125; //! rasterization and fragment shader stage. &#123; v1.posH = viewPortMatrix * v1.posH; v2.posH = viewPortMatrix * v2.posH; v3.posH = viewPortMatrix * v3.posH; if(mode == RenderMode::wire) &#123; // bresenham rasterization &#125; else if(mode == RenderMode::fill) &#123; // edge walking rasterization &#125; &#125; &#125;&#125; &emsp;&emsp;有了以上的$Pipeline$函数，我们的渲染循环逻辑的一般形式如下： 1234567891011while(!stoped)&#123; pipeline-&gt;clearBuffer(Vector4D(0.502f,0.698f,0.800f,1.0f)); pipeline-&gt;drawIndex(RenderMode::fill); pipeline-&gt;swapBuffer(); emit frameOut(pipeline-&gt;output()); ++ fps;&#125; 光栅化算法&emsp;&emsp;顶点着色器处理的还是一个个离散的几何顶点，在顶点着色器之后我们还需要进行光栅化操作，将几何覆盖的屏幕像素计算出来，送入片元着色器计算每个点的像素数据。光栅化一般有两种模式：一种是线框模式，即只描绘几何的边；二是填充模式，即将几何的面片全部填充完。Bresenham算法是经典的描线算法，它采用迭代的形式将所需的算术操作降低到最少。除此之外还有DDA描线算法，效率上不如Bresenham算法，所以我没有实现。 Bresenham描线算法&emsp;&emsp;我们要描绘的是从$(x_0,y_0)$到$(x_1,y_1)$的一条直线线段。一些数学符号标记如下： \\Delta x= x_1-x_0>0,\\ \\Delta y=y_1-y_0>0,\\ m=\\frac{\\Delta y}{\\Delta x}&emsp;&emsp;其中$m$即直线线段的斜率，为了便于讨论，我们假设$|m|\\leq 1$，其他情况很容易推广。 &emsp;&emsp;在如上的情况下，Bresenham算法从$x=x_0$开始，每次将$x$坐标值加一，然后推算相应的$y$坐标值。记第$i$次迭代获得的点为$(x_i,y_i)$。那么第$i+1$次迭代时获取的点就在$(\\overline x_i+1,\\overline y_i)$和$(\\overline x_i+1,\\overline y_i+1)$这两个中选取。那如何判断应该选哪个呢？即选择这两个点之一的判断标准是什么？直观上，我们应该选取距离的直线线段在该$y$轴上的交点最近的点，如下图1所示。 图1 判别标准 &emsp;&emsp;直线的一般表达式为$y=mx+B$，$m$为直线的斜率，那么$(x_{i+1},y_{i+1})$表示为如下（注意$y_{i+1}$表示的是直线在$x_{i+1}$上真正的$y$值）： x_{i+1}=x_i+1\\\\ y_{i+1}=mx_{i+1}+B=m(x_i+1)+B \\tag {2} 图2 交点到右边的点、右上的点的距离 &emsp;&emsp;故$d_{upper}$和$d_{lower}$的取值如下： d_{upper}=\\overline y_i+1-\\overline y_{i+1}=\\overline y_i+1-m\\overline x_{i+1}-B\\\\ d_{lower}=y_{i+1}-\\overline y_i=mx_{i+1}+B-\\overline y_i \\tag {3}&emsp;&emsp;显然，如果$d_{lower}-d_{upper}&gt;0$，则应该取右上方的点；如果$d_{lower}-d_{upper}0$的符号。 d_{lower}-d_{upper}=m(x_i+1)+B-\\overline y_i-(\\overline y_i+1-m(x_i+1)-B)\\\\ =2m(x_i+1)-2\\overline y_i+2B-1 \\tag {4}&emsp;&emsp;式$(4)$中的$m$是直线的斜率，因此将式$(4)$作为判断标准需要做非常昂贵的浮点数除法运算。为了消去除法，注意到$m=\\frac{\\Delta y}{\\Delta x}$，两边同时乘上$\\Delta x&gt;0$，正负符号不变。 p_i=\\Delta x\\cdot (d_{lower}-d_{upper}) =2\\Delta y\\cdot(x_i+1)-2\\Delta x\\cdot \\overline y_i+(2B-1)\\Delta x\\\\ =2\\Delta y\\cdot x_i-2\\Delta x\\cdot\\overline y_i+c\\\\ where \\ \\ c=(2B-1)\\Delta x+2\\Delta y \\tag {5}&emsp;&emsp;所以可以用$p_i$的符号作为选取的标准。但是，式$(5)$的计算能够进一步简化，考虑$p_i$和$p_{i+1}$（注意我们根据$p_i$的符号来选取$\\overline y_{i+1}$）： p_{i+1}-p_{i} = (2\\Delta y\\cdot x_{i+1}-2\\Delta x\\cdot\\overline y_{i+1}+c) - (2\\Delta y\\cdot x_i-2\\Delta x\\cdot\\overline y_i+c) \\\\= 2\\Delta y-2\\Delta x(\\overline y_{i+1}-\\overline y_i) \\tag {6}&emsp;&emsp;若$p_i\\leq 0$，那么选择右边的点，此时$\\overline y_{i+1}=\\overline y_i$，那么有： p_{i+1}=p_i+2\\Delta y \\tag {7}&emsp;&emsp;若$p_i&gt;0$，那么选择右上角的点，此时$\\overline y_{i+1}=\\overline y_i+1$，那么有： p_{i+1}=p_i+2\\Delta y-2\\Delta x \\tag {8}&emsp;&emsp;所以我们可以根据$p_i$的符号快速计算出$p_{i+1}$的符号，如此迭代下去： Bresenham Algorithm: $draw (x_0, y_0);$ Calculate $\\Delta x$,$\\Delta y$,$2\\Delta y$,$2\\Delta y-2\\Delta x$,$p_0=2\\Delta y-\\Delta x$; for $x$ from $x_0$ to $x_1$: &emsp;&emsp;if $p_i\\leq 0$ &emsp;&emsp;&emsp;&emsp;draw $(x_{i+1},\\overline y_{i+1})=(x_i+1,\\overline y_i)$ ; &emsp;&emsp;&emsp;&emsp;compute $p_{i+1}=p_i+2\\Delta y$; &emsp;&emsp;if $p_i &gt; 0$ &emsp;&emsp;&emsp;&emsp;draw $(x_{i+1},\\overline y_{i+1})=(x_i+1,\\overline y_i+1)$ ; &emsp;&emsp;&emsp;&emsp;compute $p_{i+1}=p_i+2\\Delta y-2\\Delta x$; &emsp;&emsp;$x += 1;$ &emsp;&emsp;上面我们讨论的都是$|m|1$的情况呢？其实这是对称的，这时把$x$看成$y$，把$y$看成$x$即可。另外，当$\\Delta x &lt;0$时，我们的$x$不是递增$1$，而是递减$1$，具体实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465void Pipeline::bresenhamLineRasterization(const VertexOut &amp;from, const VertexOut &amp;to)&#123; int dx = to.posH.x - from.posH.x; int dy = to.posH.y - from.posH.y; int stepX = 1, stepY = 1; // judge the sign if(dx &lt; 0) &#123; stepX = -1; dx = -dx; &#125; if(dy &lt; 0) &#123; stepY = -1; dy = -dy; &#125; int d2x = 2*dx, d2y = 2*dy; int d2y_minus_d2x = d2y - d2x; int sx = from.posH.x; int sy = from.posH.y; VertexOut tmp; // slope &lt; 1. if(dy &lt;= dx) &#123; int flag = d2y - dx; for(int i = 0;i &lt;= dx;++ i) &#123; // linear interpolation tmp = lerp(from, to, static_cast&lt;double&gt;(i)/dx); // fragment shader m_backBuffer-&gt;drawPixel(sx,sy,m_shader-&gt;fragmentShader(tmp)); sx += stepX; if(flag &lt;= 0) flag += d2y; else &#123; sy += stepY; flag += d2y_minus_d2x; &#125; &#125; &#125; // slope &gt; 1. else &#123; int flag = d2x - dy; for(int i = 0;i &lt;= dy;++ i) &#123; // linear interpolation tmp = lerp(from, to, static_cast&lt;double&gt;(i)/dy); // fragment shader m_backBuffer-&gt;drawPixel(sx,sy,m_shader-&gt;fragmentShader(tmp)); sy += stepY; if(flag &lt;= 0) flag += d2x; else &#123; sx += stepX; flag -= d2y_minus_d2x; &#125; &#125; &#125;&#125; Edge-Walking三角形填充算法&emsp;&emsp;三角形光栅化填充对输入给定的三个三角形顶点，计算这个三角区域覆盖的所有像素。三角形填充的光栅化算法有很多种，这里仅实现了Edge-Walking算法，此外还有Edge-Equation算法。关于Edge-Walking算法的前世今生我不再赘述了，这个算法的思路比较简单，但是实现起来比较麻烦一点。 &emsp;&emsp;话不多少，直接上伪代码（懒得自己写了伪代码了）： &emsp;&emsp;大致的思想就是从上往下（或从下往上）扫描，获取每对$X_L$、$X_R$，然后在$[X_L,X_R]$范围内从左到右扫描。显然就是双重循环。一般，我们的三角形光栅化对象有如下四种情况： 图3 四类三角形 &emsp;&emsp;先来看平底三角形的情况，如下图4所示。显然，平底三角形很容易地实现从下往上扫面，竖直方向上仅需考虑左右两条边。当然这里有个问题，就是如何确定$X_L$和$X_R$？如果直接采用算法伪代码中的利用$dx/dy$迭代获取$X$值，因为$X$值是整数，而$dx/dy$是浮点数，当$dx/dy&lt;1$时，把$dx/dy$加到$X$上面计算机对整数类型坐标自动向下取整，结果相当于没加。（即便是浮点数类型，最终也要取整，因为屏幕空间的像素坐标必须是整数） 图4 平底三角形 &emsp;&emsp;一种解决方案就是线性插值，算法从下往上扫描时，$y-=1$，我们根据当前的$y$值来获取$x$值： X_L = (1.0f-\\frac{y1-y}{y1-y0})*x1+\\frac{y1-y}{y1-y0}*x0 \\\\ X_y = (1.0f-\\frac{y2-y}{y2-y0})*x2+\\frac{y2-y}{y2-y0}*x0&emsp;&emsp;平顶的三角形光栅化亦类似，不再赘述。那么除了平底和平顶的情况之外，我们该如何处理其余的情况？一个技巧就是将其他情况的三角形分割乘一个平底三角形、一个平顶三角形，如下图所示： 图5 三角形分割 &emsp;&emsp;这样我们通过调用平底三角形光栅化方法、平顶三角形光栅化方法即可实现一般情况的三角形光栅化： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114void Pipeline::scanLinePerRow(const VertexOut &amp;left, const VertexOut &amp;right)&#123; VertexOut current; int length = right.posH.x - left.posH.x + 1; for(int i = 0;i &lt;= length;++i) &#123; // linear interpolation double weight = static_cast&lt;double&gt;(i)/length; current = lerp(left, right, weight); current.posH.x = left.posH.x + i; current.posH.y = left.posH.y; // fragment shader m_backBuffer-&gt;drawPixel(current.posH.x, current.posH.y, m_shader-&gt;fragmentShader(current)); &#125;&#125;void Pipeline::rasterTopTriangle(VertexOut &amp;v1, VertexOut &amp;v2, VertexOut &amp;v3)&#123; VertexOut left = v2; VertexOut right = v3; VertexOut dest = v1; VertexOut tmp, newleft, newright; if(left.posH.x &gt; right.posH.x) &#123; tmp = left; left = right; right = tmp; &#125; int dy = left.posH.y - dest.posH.y + 1; for(int i = 0;i &lt; dy;++i) &#123; double weight = 0; if(dy != 0) weight = static_cast&lt;double&gt;(i)/dy; newleft = lerp(left, dest, weight); newright = lerp(right, dest, weight); newleft.posH.y = newright.posH.y = left.posH.y - i; scanLinePerRow(newleft, newright); &#125;&#125;void Pipeline::rasterBottomTriangle(VertexOut &amp;v1, VertexOut &amp;v2, VertexOut &amp;v3)&#123; VertexOut left = v1; VertexOut right = v2; VertexOut dest = v3; VertexOut tmp, newleft, newright; if(left.posH.x &gt; right.posH.x) &#123; tmp = left; left = right; right = tmp; &#125; int dy = dest.posH.y - left.posH.y + 1; for(int i = 0;i &lt; dy;++i) &#123; double weight = 0; if(dy != 0) weight = static_cast&lt;double&gt;(i)/dy; newleft = lerp(left, dest, weight); newright = lerp(right, dest, weight); newleft.posH.y = newright.posH.y = left.posH.y + i; scanLinePerRow(newleft, newright); &#125;&#125;void Pipeline::edgeWalkingFillRasterization(const VertexOut &amp;v1, const VertexOut &amp;v2, const VertexOut &amp;v3)&#123; // split the triangle into two part VertexOut tmp; VertexOut target[3] = &#123;v1, v2,v3&#125;; if(target[0].posH.y &gt; target[1].posH.y) &#123; tmp = target[0]; target[0] = target[1]; target[1] = tmp; &#125; if(target[0].posH.y &gt; target[2].posH.y) &#123; tmp = target[0]; target[0] = target[2]; target[2] = tmp; &#125; if(target[1].posH.y &gt; target[2].posH.y) &#123; tmp = target[1]; target[1] = target[2]; target[2] = tmp; &#125; // bottom triangle if(equal(target[0].posH.y,target[1].posH.y)) &#123; rasterBottomTriangle(target[0],target[1],target[2]); &#125; // top triangle else if(equal(target[1].posH.y,target[2].posH.y)) &#123; rasterTopTriangle(target[0], target[1], target[2]); &#125; // split it. else &#123; double weight = static_cast&lt;double&gt;(target[1].posH.y-target[0].posH.y)/(target[2].posH.y-target[0].posH.y); VertexOut newPoint = lerp(target[0],target[2],weight); newPoint.posH.y = target[1].posH.y; rasterTopTriangle(target[0], newPoint, target[1]); rasterBottomTriangle(newPoint,target[1],target[2]); &#125;&#125; 程序结果&emsp;&emsp;最终，不借用任何图形接口通过自己实现的光栅化算法画出了三角形： 参考资料$[1]$ https://blog.csdn.net/cppyin/article/details/6232453 $[2]$ https://blog.csdn.net/y1196645376/article/details/78937614 $[3]$ https://blog.csdn.net/y1196645376/article/details/78907914","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"http://yoursite.com/categories/Computer-Graphics/"},{"name":"Soft Renderer","slug":"Soft-Renderer","permalink":"http://yoursite.com/categories/Soft-Renderer/"}],"tags":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"http://yoursite.com/tags/Computer-Graphics/"},{"name":"Soft Renderer","slug":"Soft-Renderer","permalink":"http://yoursite.com/tags/Soft-Renderer/"},{"name":"Rasterization","slug":"Rasterization","permalink":"http://yoursite.com/tags/Rasterization/"}]},{"title":"软渲染器Soft Renderer：3D数学篇","slug":"SoftRenderer-Math","date":"2019-05-01T02:37:49.425Z","updated":"2019-05-01T02:45:14.618Z","comments":true,"path":"2019/05/01/SoftRenderer-Math/","link":"","permalink":"http://yoursite.com/2019/05/01/SoftRenderer-Math/","excerpt":"本章开始博主将手动搭建一个渲染管线，深入理解3D渲染的整个流程。线性代数中的向量和矩阵是计算机图形学的常客，深入理解和掌握对于图形渲染有着非常重要的意义，本节主要是关于3D数学库的内容。","text":"本章开始博主将手动搭建一个渲染管线，深入理解3D渲染的整个流程。线性代数中的向量和矩阵是计算机图形学的常客，深入理解和掌握对于图形渲染有着非常重要的意义，本节主要是关于3D数学库的内容。 向量 矩阵 向量&emsp;&emsp;$n$维向量本质就是一个$n$元组，从几何意义上来说，向量是有大小和方向的有向线段。向量的大小就是向量的长度（模）向量有非负的长度，而向量的方向描述了空间中向量的指向。向量的相关内容高中就已涉及，因此不再赘述。若想要重新深入了解相关内容，可以查看这个地址。 &emsp;&emsp;图形渲染中通常使用的向量为$2$到$4$维，如下分别是$2$维、$3$维、$4$维向量类的常用方法，主要是运算操作符重载以及点乘、叉乘、模、标准化、线性插值等基本操作。向量的内容简单，没什么要特别说明的。 2D向量类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Vector2D&#123;public: float x,y; // constructors Vector2D():x(0.0f), y(0.0f) &#123;&#125; Vector2D(float newX, float newY):x(newX), y(newY)&#123;&#125; Vector2D(const float * rhs):x(*rhs), y((*rhs)+1) &#123;&#125; Vector2D(const Vector2D &amp; rhs):x(rhs.x), y(rhs.y)&#123;&#125; ~Vector2D() = default; // setter,getter void set(float newX, float newY)&#123;x=newX;y=newY; &#125; void setX(float newX) &#123;x = newX;&#125; void setY(float newY) &#123;y = newY;&#125; float getX() const &#123;return x;&#125; float getY() const &#123;return y;&#125; // normalization void normalize(); Vector2D getNormalize()const; // length float getLength() const &#123; return static_cast&lt;float&gt;(sqrt(x*x + y*y));&#125; float getSquaredLength()const&#123;return static_cast&lt;float&gt;(x*x + y*y);&#125; // overloaded operators Vector2D operator+(const Vector2D &amp;rhs) const &#123;return Vector2D(x + rhs.x, y + rhs.y);&#125; Vector2D operator-(const Vector2D &amp;rhs) const &#123;return Vector2D(x - rhs.x, y - rhs.y);&#125; Vector2D operator*(const float rhs) const &#123;return Vector2D(x*rhs, y*rhs);&#125; Vector2D operator/(const float rhs) const &#123;return (rhs==0) ? Vector2D(0.0f, 0.0f) : Vector2D(x / rhs, y / rhs);&#125; bool operator==(const Vector2D &amp;rhs) const &#123;return (equal(x,rhs.x) &amp;&amp; equal(y,rhs.y));&#125; bool operator!=(const Vector2D &amp;rhs) const &#123;return !((*this)==rhs);&#125; void operator+=(const Vector2D &amp;rhs)&#123;x+=rhs.x; y+=rhs.y;&#125; void operator-=(const Vector2D &amp;rhs)&#123;x-=rhs.x; y-=rhs.y;&#125; void operator*=(const float rhs)&#123;x*=rhs;y*=rhs;&#125; void operator/=(const float rhs)&#123;if(!equal(rhs, 0.0))&#123;x/=rhs;y/=rhs;&#125;&#125; Vector2D operator-() const &#123;return Vector2D(-x, -y);&#125; Vector2D operator+() const &#123;return *this;&#125; // interpolation Vector2D lerp(const Vector2D &amp;v2,const float factor)const &#123;return (*this)*(1.0f - factor) + v2*factor;&#125; Vector2D quadraticInterpolate(const Vector2D &amp; v2, const Vector2D &amp; v3, const float factor) const &#123;return (*this)*(1.0f-factor)*(1.0f-factor) + v2*2.0f*factor*(1.0f-factor) + v3*factor*factor;&#125;&#125;; 3D向量类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Vector3D&#123;public: float x,y,z; // constructors Vector3D():x(0.0f), y(0.0f), z(0.0f)&#123;&#125; Vector3D(float newX, float newY, float newZ):x(newX), y(newY), z(newZ)&#123;&#125; Vector3D(const float * rhs):x(*rhs), y(*(rhs+1)), z(*(rhs+2))&#123;&#125; Vector3D(const Vector3D &amp;rhs):x(rhs.x), y(rhs.y), z(rhs.z)&#123;&#125; ~Vector3D() = default; // setter,getter void set(float newX, float newY, float newZ)&#123;x=newX;y=newY;z=newZ;&#125; void setX(float newX) &#123;x = newX;&#125; void setY(float newY) &#123;y = newY;&#125; void setZ(float newZ) &#123;z = newZ;&#125; float getX() const &#123;return x;&#125; float getY() const &#123;return y;&#125; float getZ() const &#123;return z;&#125; // normalization void normalize(); Vector3D getNormalized() const; // length caculation float getLength() const &#123;return static_cast&lt;float&gt;(sqrt(x*x+y*y+z*z));&#125; float getSquaredLength() const &#123;return x*x+y*y+z*z;&#125; // product float dotProduct(const Vector3D &amp;rhs) const &#123;return x*rhs.x + y*rhs.y + z*rhs.z;&#125; Vector3D crossProduct(const Vector3D &amp;rhs) const &#123;return Vector3D(y*rhs.z - z*rhs.y, z*rhs.x - x*rhs.z, x*rhs.y - y*rhs.x);&#125; // linear interpolation Vector3D lerp(const Vector3D &amp;v2, float factor) const &#123;return (*this)*(1.0f-factor) + v2*factor;&#125; Vector3D QuadraticInterpolate(const Vector3D &amp;v2, const Vector3D &amp;v3, float factor) const &#123;return (*this)*(1.0f-factor)*(1.0f-factor) + v2*2.0f*factor*(1.0f-factor) + v3*factor*factor;&#125; // overloaded operators Vector3D operator+(const Vector3D &amp;rhs) const &#123;return Vector3D(x + rhs.x, y + rhs.y, z + rhs.z);&#125; Vector3D operator-(const Vector3D &amp;rhs) const &#123;return Vector3D(x - rhs.x, y - rhs.y, z - rhs.z);&#125; Vector3D operator*(const float rhs) const &#123;return Vector3D(x*rhs, y*rhs, z*rhs);&#125; Vector3D operator/(const float rhs) const &#123;return (equal(rhs,0.0f))?Vector3D(0.0f, 0.0f, 0.0f):Vector3D(x/rhs, y/rhs, z/rhs);&#125; bool operator==(const Vector3D &amp;rhs) const &#123;return (equal(x,rhs.x) &amp;&amp; equal(y,rhs.y) &amp;&amp; equal(z,rhs.z));&#125; bool operator!=(const Vector3D &amp;rhs) const &#123;return !((*this)==rhs);&#125; void operator+=(const Vector3D &amp;rhs) &#123;x+=rhs.x;y+=rhs.y;z+=rhs.z;&#125; void operator-=(const Vector3D &amp; rhs) &#123;x-=rhs.x;y-=rhs.y;z-=rhs.z;&#125; void operator*=(const float rhs)&#123;x*=rhs;y*=rhs;z*=rhs;&#125; void operator/=(const float rhs)&#123;if(!equal(rhs,0.0f))&#123;x/=rhs; y/=rhs; z/=rhs;&#125;&#125; Vector3D operator-() const &#123;return Vector3D(-x, -y, -z);&#125; Vector3D operator+() const &#123;return *this;&#125;&#125;; 4D向量类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Vector4D&#123;public: float x,y,z,w; // constructors Vector4D():x(0.0f), y(0.0f), z(0.0f), w(0.0f)&#123;&#125; Vector4D(float newX, float newY, float newZ, float newW):x(newX), y(newY), z(newZ), w(newW)&#123;&#125; Vector4D(const float * rhs):x(*rhs), y(*(rhs+1)), z(*(rhs+2)), w(*(rhs+3))&#123;&#125; Vector4D(const Vector4D &amp;rhs):x(rhs.x), y(rhs.y), z(rhs.z), w(rhs.w)&#123;&#125; Vector4D(const Vector3D &amp; rhs): x(rhs.x), y(rhs.y), z(rhs.z), w(1.0f)&#123;&#125; ~Vector4D() = default; // setter,getter void set(float newX, float newY, float newZ, float newW)&#123;x=newX;y=newY;z=newZ;w=newW;&#125; void setX(float newX) &#123;x = newX;&#125; void setY(float newY) &#123;y = newY;&#125; void setZ(float newZ) &#123;z = newZ;&#125; void setW(float newW) &#123;w = newW;&#125; float getX() const &#123;return x;&#125; float getY() const &#123;return y;&#125; float getZ() const &#123;return z;&#125; float getW() const &#123;return w;&#125; // product float dotProduct(const Vector4D &amp;rhs) const &#123;return x*rhs.x + y*rhs.y + z*rhs.z + w*rhs.w;&#125; // linear interpolation Vector4D lerp(const Vector4D &amp;v2, float factor) const &#123;return (*this)*(1.0f-factor) + v2*factor;&#125; Vector4D QuadraticInterpolate(const Vector4D &amp;v2, const Vector4D &amp;v3, float factor) const &#123;return (*this)*(1.0f-factor)*(1.0f-factor)+v2*2.0f*factor*(1.0f-factor)+v3*factor*factor;&#125; // overloaded operators Vector4D operator+(const Vector4D &amp;rhs) const &#123;return Vector4D(x+rhs.x, y+rhs.y, z+rhs.z, w+rhs.w);&#125; Vector4D operator-(const Vector4D &amp;rhs) const &#123;return Vector4D(x-rhs.x, y-rhs.y, z-rhs.z, w-rhs.w);&#125; Vector4D operator*(const float rhs) const &#123;return Vector4D(x*rhs, y*rhs, z*rhs, w*rhs);&#125; Vector4D operator/(const float rhs) const &#123;return (equal(rhs,0.0f))?Vector4D(0.0f, 0.0f, 0.0f, 0.0f):Vector4D(x/rhs, y/rhs, z/rhs, w/rhs);&#125; bool operator==(const Vector4D &amp;rhs) const &#123;return (equal(x,rhs.x)&amp;&amp;equal(y,rhs.y)&amp;&amp;equal(z,rhs.z)&amp;&amp;equal(w,rhs.w));&#125; bool operator!=(const Vector4D &amp;rhs) const &#123;return !((*this)==rhs);&#125; void operator+=(const Vector4D &amp;rhs) &#123;x+=rhs.x;y+=rhs.y;z+=rhs.z;w+=rhs.w;&#125; void operator-=(const Vector4D &amp; rhs) &#123;x-=rhs.x;y-=rhs.y;z-=rhs.z;w-=rhs.w;&#125; void operator*=(const float rhs)&#123;x*=rhs;y*=rhs;z*=rhs;w*=rhs;&#125; void operator/=(const float rhs)&#123;if(!equal(rhs,0.0f))&#123;x/=rhs; y/=rhs; z/=rhs; w/=rhs;&#125;&#125; Vector4D operator-() const &#123;return Vector4D(-x, -y, -z, -w);&#125; Vector4D operator+() const &#123;return *this;&#125;&#125;; 矩阵&emsp;&emsp;矩阵本质就是向量的进一步扩展的，一个$n\\times m$的矩阵可看成$n$个$m$维行向量组成或者$m$个$n$维列向量组成，关于矩阵的基本概念、操作请看这里。通常我们采用方阵来描述线性变换。所谓线性变换，即变换之后保留了直线而不被弯曲，平行线依然平行，原点没有变化，但其他的几何性质如长度、角度、面积和体积可能被变换改变了。直观来说，线性变换可能“拉伸”坐标系，但不会“弯曲”或“卷折”坐标系。 &emsp;&emsp;矩阵在计算机中有行主序存储、列主序存储两种方式，行主序存储即按照顺序逐行存储，列主序存储则按照顺序逐列存储。图形学渲染中我们通常采用的是列主序的方式，以下的讨论都是列主序的矩阵存储方式。那么矩阵是如何变换向量的？ &emsp;&emsp;向量在几何上能被解释成一系列与轴平行的位移，一般来说，任意向量$\\vec v$都能写成如下的形式： \\vec v=\\left[\\begin{matrix}x\\\\y\\\\z\\end{matrix}\\right]=\\left[\\begin{matrix}x\\\\0\\\\0\\end{matrix}\\right]+\\left[\\begin{matrix}0\\\\y\\\\0\\end{matrix}\\right]+\\left[\\begin{matrix}0\\\\0\\\\z\\end{matrix}\\right]=x\\left[\\begin{matrix}1\\\\0\\\\0\\end{matrix}\\right]+y\\left[\\begin{matrix}0\\\\1\\\\0\\end{matrix}\\right]+z\\left[\\begin{matrix}0\\\\0\\\\1\\end{matrix}\\right] \\tag {1}&emsp;&emsp;公式$(1)$右边的单位向量就是$x$、$y$、$z$轴方向的向量，向量的每个坐标都表明了平行于相应坐标轴的有向位移。我们记$\\vec p$、$\\vec q$、$\\vec r$分别为公式$(1)$中右边的$x$、$y$、$z$轴的单位列向量，则有： \\vec v=x\\vec p+y\\vec q+z\\vec r=\\left[\\begin{matrix}\\vec p &\\vec q&\\vec r\\end{matrix}\\right]\\left[\\begin{matrix}x \\\\y\\\\z\\end{matrix}\\right] \\tag {2}&emsp;&emsp;向量$\\vec v$就变成了向量$\\vec p$、$\\vec q$、$\\vec r$的线性表示，向量$\\vec p$、$\\vec q$、$\\vec r$称作基向量。以上仅仅讨论的是笛卡尔坐标系，但更通用的情况是，一个$3$维坐标系能用任意$3$个线性无关的基向量表示，以列向量$\\vec p$、$\\vec q$、$\\vec r$构建$3\\times 3$的矩阵$M$： M=\\left[\\begin{matrix}\\vec p &\\vec q&\\vec r\\end{matrix}\\right]=\\left[\\begin{matrix}p_x &q_x&r_x\\\\p_y &q_y&r_y\\\\p_z &q_z&r_z\\end{matrix}\\right] \\tag {3}&emsp;&emsp;结合公式$(2)$和公式$(3)$，即有： \\vec v=M\\left[\\begin{matrix}x \\\\y\\\\z\\end{matrix}\\right] \\tag{4}&emsp;&emsp;坐标系变换矩阵的每一列（如果是行主序，就是每一行）都是该坐标系的基向量，一个点$v$右乘该矩阵就相当于执行了一次坐标系转换。求解线性变换矩阵的关键就是根据当前的坐标系求解变换之后的坐标系的基向量，然后将基向量填入向量位置！ &emsp;&emsp;一个矩阵类通常有如下方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class Matrix4x4&#123;public: float entries[16]; // constructors Matrix4x4()&#123;loadIdentity();&#125; Matrix4x4(float e0, float e1, float e2, float e3, float e4, float e5, float e6, float e7, float e8, float e9, float e10,float e11, float e12,float e13,float e14,float e15); Matrix4x4(const float *rhs); Matrix4x4(const Matrix4x4 &amp;rhs); ~Matrix4x4() = default; // setter,getter void setEntry(int position, float value); float getEntry(int position) const; Vector4D getRow(int position) const; Vector4D getColumn(int position) const; void loadIdentity(); void loadZero(); // overloaded operators Matrix4x4 operator+(const Matrix4x4 &amp; rhs) const; Matrix4x4 operator-(const Matrix4x4 &amp; rhs) const; Matrix4x4 operator*(const Matrix4x4 &amp; rhs) const; Matrix4x4 operator*(const float rhs) const; Matrix4x4 operator/(const float rhs) const; bool operator==(const Matrix4x4 &amp; rhs) const; bool operator!=(const Matrix4x4 &amp; rhs) const; void operator+=(const Matrix4x4 &amp; rhs); void operator-=(const Matrix4x4 &amp; rhs); void operator*=(const Matrix4x4 &amp; rhs); void operator*=(const float rhs); void operator/=(const float rhs); Matrix4x4 operator-() const; Matrix4x4 operator+() const &#123;return (*this);&#125; Vector4D operator*(const Vector4D rhs) const; // inverse, transpose void inverted(); Matrix4x4 getInverse() const; void transpose(); Matrix4x4 getTranspose() const; void invertTranspose(); Matrix4x4 getInverseTranspose() const; // operation on space void setTranslation(const Vector3D &amp; translation); void setScale(const Vector3D &amp; scaleFactor); void setRotationAxis(const double angle, const Vector3D &amp; axis); void setRotationX(const double angle); void setRotationY(const double angle); void setRotationZ(const double angle); void setRotationEuler(const double angleX, const double angleY, const double angleZ); void setPerspective(float fovy, float aspect, float near, float far); void setPerspective(float left, float right, float bottom, float top, float near, float far); void setOrtho(float left, float right, float bottom, float top, float near, float far);&#125;; 线性变换、仿射变换&emsp;&emsp;满足$F(a+b)=F(a)+F(b)$和$F(ka)=kF(a)$的映射$F(a)$就是线性的。对于映射$F(a)=Ma$，当$M$为任意方阵时，也可以说明$F$映射是一个线性变换。在计算机图形学中，缩放、旋转的变换操作都是线性的，但是平移不是线性变换。 &emsp;&emsp;具有$v’=Mv’+b$形式的变换都是仿射变换。平移作为最常用的变换之一，然而却不是线性变换；所以为了包括平移变换提出了仿射变换。仿射变换是指线性变换后接着平移。因此，仿射变换的集合是线性变换的超集，任何线性变换都是仿射变换，但不是所有的仿射变换都是线性变换。为了统一用矩阵表示低维度的仿射变换，我们可以通过高维度的线性变换来完成，为此引入了$4$维齐次坐标。（当然引入第$4$维$w$还有其他的用途，如当$w=0$时，可解释为无穷远的“点”，其意义是描述方向），关于齐次坐标的更多内容请查看这里。 &emsp;&emsp;从而，对于高维度来说只是经历了一次切变+投影变换就可以实现低维度的平移（更多内容查看这里），在$3D$渲染中，我们采用$4\\times 4$的矩阵做相应的变换。关于平移和缩放不再赘述： 123456789101112131415void Matrix4x4::setTranslation(const Vector3D &amp;translation)&#123; loadIdentity(); entries[12] = translation.x; entries[13] = translation.y; entries[14] = translation.z;&#125;void Matrix4x4::setScale(const Vector3D &amp;scaleFactor)&#123; loadIdentity(); entries[0] = scaleFactor.x; entries[5] = scaleFactor.y; entries[10] = scaleFactor.z;&#125; 绕任意轴旋转&emsp;&emsp;在3D中，绕坐标轴旋转，而不是绕点旋转，此时首先需要定义的是何为旋转正方向： 左手坐标系中定义此方向的规则为左手法则。首先，要明确旋转轴指向哪个方向。当然，旋转轴在理论上是无限延伸的，但我们还是要认为它有正端点和负端点。与笛卡尔坐标轴定义坐标系相同，左手法则是这样的:伸出左手，大拇指向上，其余手指弯曲。大拇指指向旋转轴的正方向，此时，四指弯曲的方向就是旋转的正方向。右手坐标系则根据右手法则利用右手判断旋转正方向，本文讨论的是常见的右手坐标系。 &emsp;&emsp;在旋转变换中，一个常见的特殊情况就是绕$x$轴、绕$y$轴、绕$z$轴旋转，这类的旋转矩阵求解比较简单，只需牢牢记住列主序矩阵的列向量就是变换后的坐标系的基向量即可快速推导出相应的旋转矩阵： R_x(\\theta)=\\left[ \\begin{matrix} 1&0&0\\\\ 0&cos\\theta&-sin\\theta\\\\ 0&sin\\theta&cos\\theta \\end{matrix}\\right] \\\\ R_y(\\theta)=\\left[\\begin{matrix}cos\\theta&0&sin\\theta\\\\0&1&0\\\\-sin\\theta&0&cos\\theta \\end{matrix}\\right]\\\\ R_z(\\theta)=\\left[\\begin{matrix}cos\\theta&-sin\\theta&0\\\\ sin\\theta&cos\\theta&0\\\\0&0&1\\end{matrix}\\right] \\tag {5}1234567891011121314151617181920212223242526void Matrix4x4::setRotationX(const double angle)&#123; loadIdentity(); entries[5] = static_cast&lt;float&gt;(cos(M_PI*angle/180)); entries[6] = static_cast&lt;float&gt;(sin(M_PI*angle/180)); entries[9] = -entries[6]; entries[10] = entries[5];&#125;void Matrix4x4::setRotationY(const double angle)&#123; loadIdentity(); entries[0] = static_cast&lt;float&gt;(cos(M_PI*angle/180)); entries[2] = -static_cast&lt;float&gt;(sin(M_PI*angle/180)); entries[8] = -entries[2]; entries[10] = entries[0];&#125;void Matrix4x4::setRotationZ(const double angle)&#123; loadIdentity(); entries[0] = static_cast&lt;float&gt;(cos(M_PI*angle/180)); entries[1] = static_cast&lt;float&gt;(sin(M_PI*angle/180)); entries[4] = -entries[1]; entries[5] = entries[0];&#125; &emsp;&emsp;但是更一般的情况是绕任意轴进行旋转，构建这样的矩阵稍微有点麻烦，我们接下来就做一些绕任意轴旋转的矩阵构建推到。在这里我们不考虑平移，因而围绕旋转的轴一定是通过原点的。如下图1所示，将$\\vec v$旋转到$\\vec v ‘$，任意轴用单位向量$\\vec n$表示，绕$\\vec n$旋转$\\theta$角度的矩阵记为$R(\\vec n, \\theta)$，$\\vec v’$是向量绕轴$\\vec n$旋转后的向量，即$\\vec v’=R(\\vec n,\\theta)\\vec v$。 图1 绕任意轴旋转 &emsp;&emsp;我们的目标就是用$\\vec v$、$\\vec n$和$\\theta$来表示$\\vec v’$，从而构造出$R(\\vec n, \\theta)$。首先将$\\vec v$分解成平行于$\\vec n$的向量$\\vec v_{||}$和垂直于$\\vec n$的分量$\\vec v_{h}$，而$\\vec v’_{h}$是垂直于$\\vec n$的分向量。注意，$\\vec n$是单位向量，但$\\vec v$不是单位向量，可得$\\vec v$在$\\vec n$方向的投影向量$\\vec v_{||}$为： \\vec v_{||}=(\\vec v\\cdot\\vec n)\\vec n \\tag {6}&emsp;&emsp;从而根据$\\vec v_{||}$和$\\vec v$可知$\\vec v_{h}$和$w$，$w$是垂直于$\\vec n$和$\\vec v_{h}$的向量： \\vec v_{h}=\\vec v-\\vec v_{||} \\tag {7} w=\\vec n \\times \\vec v_{h} = \\vec n\\times (\\vec v-\\vec v_{||})\\\\ =\\vec n\\times\\vec v-\\vec n\\times\\vec v_{||}=\\vec n\\times\\vec v-0=\\vec n\\times \\vec v \\tag{8}&emsp;&emsp;$\\vec w$和$\\vec v_{h}$相互垂直，$\\vec w$、$\\vec v_{h}$和$\\vec v’_{h}$在同一个平面上，$\\vec v’_{h}$和$\\vec v_{h}$的夹角为$\\theta$，从而$\\vec v’_{h}$可由$\\vec w$和$\\vec v_{h}$线性表示为： \\vec v'_{h}=cos\\theta\\vec v_{h}+sin\\theta\\vec w\\\\ =cos\\theta(\\vec v-(\\vec v\\cdot\\vec n)\\vec n)+sin\\theta(\\vec n\\times\\vec v)\\tag {9}&emsp;&emsp;最后，根据公式$(6)$和公式$(9)$我们已知$\\vec v_{||}$和$\\vec v’_{h}$，从而可以得出$\\vec v’$： \\vec v'=\\vec v_{||}+\\vec v'_{h}\\\\ =cos\\theta(\\vec v-(\\vec v\\cdot\\vec n)\\vec n)+sin\\theta(\\vec n\\times\\vec v)+(\\vec v\\cdot\\vec n)\\vec n \\tag {10}&emsp;&emsp;由公式$(10)$可知，我们已经用$\\vec v$、$\\vec n$和$\\theta$表示$\\vec v’$，那如何根据上述的公式$(10)$构建旋转矩阵$R(\\vec n, \\theta)$？还是那个思路：列主序变换矩阵的列向量就是变换后的坐标系的基向量。我们只需求出笛卡尔坐标系的$\\vec x$、$\\vec y$、$\\vec z$三个轴方向上的基向量按照公式$(10)$旋转之后的基向量$\\vec x’$、$\\vec y’$、$\\vec z’$，然后填入矩阵$R(\\vec n, \\theta)$即可，以$\\vec x=[1\\ \\ 0 \\ \\ 0]^T$为例： \\vec x'=cos\\theta(\\vec x-(\\vec x\\cdot\\vec n)\\vec n)+sin\\theta(\\vec n\\times\\vec x)+(\\vec x\\cdot\\vec n)\\vec n =\\left[\\begin{matrix} n^2_x(1-cos\\theta)+cos\\theta \\\\n_xn_y(1-cos\\theta)+n_zsin\\theta \\\\n_xn_z(1-cos\\theta)-n_ysin\\theta) \\end{matrix}\\right] \\tag {11}&emsp;&emsp;$\\vec y=[0\\ \\ 1\\ \\ 0]^T$和$\\vec z=[0\\ \\ 0\\ \\ 1]^T$同理： \\vec y' =\\left[\\begin{matrix} n_xn_y(1-cos\\theta)-n_zsin\\theta \\\\n^2_y(1-cos\\theta)+cos\\theta \\\\n_yn_z(1-cos\\theta)+n_xsin\\theta \\end{matrix}\\right] \\tag {12} \\vec z' =\\left[\\begin{matrix} n_xn_z(1-cos\\theta)+n_ysin\\theta \\\\n_yn_z(1-cos\\theta)-n_xsin\\theta \\\\n^2_z(1-cos\\theta)+cos\\theta \\end{matrix}\\right] \\tag {13}&emsp;&emsp;将$\\vec x’$、$\\vec y’$、$\\vec z’$合并到$R(\\vec n, \\theta)$中： R(\\vec n, \\theta) =\\left[\\begin{matrix} \\vec x'&\\vec y'&\\vec z' \\end{matrix}\\right] \\\\=\\begin{bmatrix} {n_x}^2(1-cos\\theta)+cos\\theta&n_xn_y(1-cos\\theta)-n_zsin\\theta&n_xn_z(1-cos\\theta)+n_ysin\\theta \\\\n_xn_y(1-cos\\theta)+n_zsin\\theta&n^2_y(1-cos\\theta)+cos\\theta&n_yn_z(1-cos\\theta)-n_xsin\\theta \\\\n_xn_z(1-cos\\theta)-n_ysin\\theta)&n_yn_z(1-cos\\theta)+n_xsin\\theta&n^2_z(1-cos\\theta)+cos\\theta \\end{bmatrix} \\tag {14}12345678910111213141516171819202122void Matrix4x4::setRotationAxis(const double angle, const Vector3D &amp;axis)&#123; Vector3D u = axis.getNormalized(); float sinAngle = static_cast&lt;float&gt;(sin(M_PI*angle/180)); float cosAngle = static_cast&lt;float&gt;(cos(M_PI*angle/180)); float oneMinusCosAngle = 1.0f - cosAngle; loadIdentity(); entries[0] = (u.x)*(u.x) + cosAngle*(1-(u.x)*(u.x)); entries[4] = (u.x)*(u.y)*(oneMinusCosAngle) - sinAngle*u.z; entries[8] = (u.x)*(u.z)*(oneMinusCosAngle) + sinAngle*u.y; entries[1] = (u.x)*(u.y)*(oneMinusCosAngle) + sinAngle*u.z; entries[5] = (u.y)*(u.y) + cosAngle*(1-(u.y)*(u.y)); entries[9] = (u.y)*(u.z)*(oneMinusCosAngle) - sinAngle*u.x; entries[2] = (u.x)*(u.z)*(oneMinusCosAngle) - sinAngle*u.y; entries[6] = (u.y)*(u.z)*(oneMinusCosAngle) + sinAngle*u.x; entries[10] = (u.z)*(u.z) + cosAngle*(1-(u.z)*(u.z));&#125; 透视投影、正交投影&emsp;&emsp;$3D$空间中的物体最终都要通过投影显示到$2D$的屏幕上，这一过程就是投影变换。投影变换矩阵将视图空间中的顶点数据变换到裁剪空间，裁剪空间中的顶点最后通过透视除法被变换到标准化设备坐标（$NDC$）。通常由两类投影：透视投影、正交投影。 透视投影矩阵&emsp;&emsp;关于透视投影矩阵的前世今生我不过多说，直接上透视投影矩阵的推导过程。一个视锥体我们目前用六个参数表示：$left$，$right$，$bottom$，$top$，$near$，$far$，简写为$l$、$r$、$b$、$t$、$n$和$f$，即视锥体的六个面。我们的目标就是将视图空间中在视锥体内的点变换到标准化设备坐标中的立方体内。即$x$轴方向从$[l,r]$映射到$[-1,1]$，$y$轴方向从$[b,t]$映射到$[-1,1]$，$z$轴方向从$[-n,-f]$映射到$[-1,1]$。 &emsp;&emsp;可能你会觉得奇怪，$z$轴方向为什么是从$[-n,-f]$映射到$[-1,1]$？这是因为摄像机空间的坐标系是右手坐标系，在视图空间中摄像机是朝向视图坐标系的$z$轴的负方向，如下图左边所示，$+Y$、$+Z$、$+X$标准摄像机坐标系的三个轴，而摄像机的观察视锥体是朝向$-Z$方向的。而$NDC$又是左手坐标系，朝向$+Z$方向，所以我们要取负。 图2 透视投影视锥和标准化设备坐标 图3 从-Y方向看去的视锥横截面 图4 从-X方向看去的视锥横截面 &emsp;&emsp;在视锥体中的顶点$(x_e,y_e,z_e)$被投影到视锥体的近平面，近平面上的点我们记为$(x_p,y_p,-n)$。如图3和图4所示，根据三角形相似的原理，我们有： \\frac{x_p}{x_e}=\\frac{-n}{z_e}\\ \\rightarrow\\ x_p=\\frac{-n\\cdot x_e}{z_e}=\\frac{n\\cdot x_e}{-z_e} \\tag {15} \\frac{y_p}{y_e}=\\frac{-n}{y_e}\\ \\rightarrow\\ y_p=\\frac{-n\\cdot y_e}{z_e}=\\frac{n\\cdot y_e}{-z_e} \\tag {16}&emsp;&emsp;注意到公式$(15)$和$(16)$中分母都是一个$-z_e$，这与我们将裁剪空间中的顶点做透视除法相对应，透视投影然后做透视除法如下公式$(17)$、$(18)$所示： \\left( \\begin{matrix} x_{clip}\\\\ y_{clip}\\\\ z_{clip}\\\\ w_{clip} \\end{matrix} \\right) =M_{projection}\\cdot \\left( \\begin{matrix} x_{eye}\\\\ y_{eye}\\\\ z_{eye}\\\\ w_{eye} \\end{matrix} \\right) \\tag {17} \\left( \\begin{matrix} x_{ndc}\\\\ y_{ndc}\\\\ z_{ndc} \\end{matrix} \\right) = \\left( \\begin{matrix} x_{clip}/w_{clip}\\\\ y_{clip}/w_{clip}\\\\ z_{clip}/w_{clip} \\end{matrix} \\right) \\tag {18}&emsp;&emsp;为了便于构建矩阵（$x_e$和$y_e$均与$-z_e$相除，不好构建矩阵），我们令裁剪空间中的$w_{clip}$为$-z_e$，将除以$-z_e$的这一步挪到了透视除法去做。故目前的透视矩阵就变为： \\left( \\begin{matrix} x_{c}\\\\ y_{c}\\\\ z_{c}\\\\ w_{c} \\end{matrix} \\right) = \\left( \\begin{matrix} .&.&.&.\\\\ .&.&.&.\\\\ .&.&.&.\\\\ 0&0&-1&0 \\end{matrix} \\right) \\left( \\begin{matrix} x_{e}\\\\ y_{e}\\\\ z_{e}\\\\ w_{e} \\end{matrix} \\right) \\tag {19}&emsp;&emsp;其中”$.$”均表示未知。得到在近平面的$x_p$和$y_p$之后，我们还要将$x_p$映射到$[-1,1]$范围，同理$y_p$也是。以$x_p$为例，我们知道其值域为$[l,r]$。为了将$x_p$其映射到$[-1,1]$，我们首先将其映射到$[0,1]$，不难得到如下式子： \\frac{x_p-l}{r-l}\\in[0,1] \\tag {20}&emsp;&emsp;式$(20)$乘上一个$2$再减去$1$就映射到了$[-1,1]$，映射之后记为$x_n$： x_n=2\\frac{x_p-l}{r-l}-1=\\frac{2x_p}{r-l}-\\frac{r+l}{r-l}\\in[-1,1] \\tag {21}&emsp;&emsp;同理$y_p$到$y_n$的映射： y_n=\\frac{2y_p}{r-l}-\\frac{t+b}{t-b}\\in[-1,1] \\tag {22}&emsp;&emsp;然后将公式$(15)$中的$x_p$带入公式$(21)$，将公式$(16)$中的$y_p$带入公式$(22)$，以$x_p$为例： x_n=\\frac{2x_p}{r-l}-\\frac{r+l}{r-l} =\\frac{2\\frac{n\\cdot x_e}{-z_e}}{r-l}-\\frac{r+l}{r-l}\\\\ =\\frac{2n\\cdot x_e}{(r-l)(-z_e)}-\\frac{r+l}{r-l} =\\frac{\\frac{2n}{r-l}\\cdot x_e}{-z_e}-\\frac{r+l}{r-l}\\\\ =\\frac{\\frac{2n}{r-l}\\cdot x_e}{-z_e}+\\frac{\\frac{r+l}{r-l}\\cdot z_e}{-z_e} =\\underbrace{(\\frac{2n}{r-l}\\cdot x_e+\\frac{r+l}{r-l}\\cdot z_e)}_{x_c}/-z_e \\tag {23}&emsp;&emsp;其中$x_c$即公式$(19)$中的裁剪空间中的$x$轴坐标值。$y_p$同理可得$y_c$: y_n =\\underbrace{(\\frac{2n}{t-b}\\cdot y_e+\\frac{t+b}{t-b}\\cdot z_e)}_{y_c}/-z_e \\tag {24}&emsp;&emsp;现在我们已经知道了$x_c$和$y_c$分辨关于$x_e$、$y_e$以及$z_e$的表达形式，我们可以填充式$(19)$中的投影矩阵第一行与第二行： \\left( \\begin{matrix} x_{c}\\\\ y_{c}\\\\ z_{c}\\\\ w_{c} \\end{matrix} \\right) = \\left( \\begin{matrix} \\frac{2n}{r-l}&0&\\frac{r+l}{r-l}&0\\\\ 0&\\frac{2n}{t-b}&\\frac{t+b}{t-b}&0\\\\ 0&0&A&B\\\\ 0&0&-1&0 \\end{matrix} \\right) \\left( \\begin{matrix} x_{e}\\\\ y_{e}\\\\ z_{e}\\\\ w_{e} \\end{matrix} \\right) \\tag {25}&emsp;&emsp;现在我们还剩下投影矩阵的第三行还不知道。因为我们知道$z$的投影与$x_e$和$y_e$无关，只与$z_e$、$w_e$有关，故可以假设投影矩阵的第三行如上式$(25)$所示，$A$和$B$就是我们假设的要求解的未知表达式。此外，在视图空间中的$w_e$是等于$1$的，$w_c$即前面提到的$-z_e$，从而有： z_n=z_c/w_c=\\frac{Az_e+Bw_e}{-z_e}=\\frac{Az_e+B}{-z_e} \\tag {26}&emsp;&emsp;为了求出公式$(26)$中的$A$和$B$，我们取两个极端的例子：在$-n$处的$z$值被映射到$-1$，在$-f$处的$z$值被映射到$1$，将$(z_n,z_e)=(-1,-n)$和$(z_n,z_e)=(1,-f)$带入式$(26)$中，可得方程组： \\begin{cases} \\frac{-An+B}{n}=-1\\\\ \\frac{-Af+B}{f}=1\\\\ \\end{cases}\\ \\rightarrow\\ \\begin{cases} {-An+B}=-n\\\\ {-Af+B}=f\\\\ \\end{cases} \\tag {27}&emsp;&emsp;求解方程$(27)$，可得$A$与$B$如下所示： A=-\\frac{f+n}{f-n}\\\\ B=-\\frac{2fn}{f-n} \\tag {28}&emsp;&emsp;将公式$(28)$带入公式$(26)$中： z_n=\\underbrace{(-\\frac{f+n}{f-n}z_e-\\frac{2fn}{f-n})}_{z_c}/{-z_e} \\tag {29}&emsp;&emsp;我们最终得到了$z_c$关于$z_e$的表达式，将$A$与$B$填入式$(25)$的投影矩阵即可，$M_{projection}$就是我们一直在寻求的透视投影矩阵： M_{projection}= \\left( \\begin{matrix} \\frac{2n}{r-l}&0&\\frac{r+l}{r-l}&0\\\\ 0&\\frac{2n}{t-b}&\\frac{t+b}{t-b}&0\\\\ 0&0&-\\frac{f+n}{f-n}&-\\frac{2fn}{f-n}\\\\ 0&0&-1&0 \\end{matrix} \\right) \\tag {30}&emsp;&emsp;公式$(30)$中的透视投影矩阵只是一个通用的形式，在视图空间中的视锥体通常都是关于$x$轴和$y$轴对称的，从而有$r=-l$、$t=-b$，将式$(30)$简化成如下形式： M_{projection}= \\left( \\begin{matrix} \\frac{2n}{r-l}&0&0&0\\\\ 0&\\frac{2n}{t-b}&0&0\\\\ 0&0&-\\frac{f+n}{f-n}&-\\frac{2fn}{f-n}\\\\ 0&0&-1&0 \\end{matrix} \\right) \\tag {31}&emsp;&emsp;&emsp;但是通常我们传入构建透视矩阵函数的参数是$fovy$（$y$轴方向的视域角）、$aspect$（屏幕的宽高比）、$near$（近平面）以及$far$（远平面），如何根据这些参数构造式$(31)$的透视投影矩阵呢？注意到$r-l=width$即近平面宽度，$t-b=height$即近平面的高度，我们可以根据$fovy$和$aspect$得出$width$和$height$，具体细节不再赘述： r-l=width=2*near*aspect*tan(fovy/2)\\\\ t-b=height=2*near*tan(fovy/2) M_{projection}= \\left( \\begin{matrix} \\frac{1}{aspect*tan(fovy/2)}&0&0&0\\\\ 0&\\frac{1}{tan(fovy/2)}&0&0\\\\ 0&0&-\\frac{f+n}{f-n}&-\\frac{2fn}{f-n}\\\\ 0&0&-1&0 \\end{matrix} \\right) \\tag {32}123456789101112void Matrix4x4::setPerspective(float fovy, float aspect, float near, float far)&#123; loadZero(); // convert fov from degrees to radians float rFovy = fovy*M_PI/180; const float tanHalfFovy = tanf(static_cast&lt;float&gt;(rFovy*0.5f)); entries[0] = 1.0f/(aspect*tanHalfFovy); entries[5] = 1.0f/(tanHalfFovy); entries[10] = -(far+near)/(far-near); entries[11] = -1.0f; entries[14] = (-2.0f*near*far)/(far-near);&#125; 正交投影矩阵&emsp;&emsp;理解了透视投影矩阵的构造之后，正交投影就简单太多了，正交投影只需做简单的线性映射就行了。只需将$x$轴方向从$[l,r]$映射到$[-1,1]$，$y$轴方向从$[b,t]$映射到$[-1,1]$，$z$轴方向从$[-n,-f]$映射到$[-1,1]$，而这个映射的过程很简单，正如前面公式$(20)$和$(21)$那样，先映射到$[0,1]$，再映射到$[0,2]$，最后映射到$[-1,1]$，这个过程我也不细说了，直接上结果： M_{projection}= \\left( \\begin{matrix} \\frac{2}{r-l}&0&0&-\\frac{r+l}{r-l}\\\\ 0&\\frac{2}{t-b}&0&-\\frac{t+b}{t-b}\\\\ 0&0&\\frac{-2}{f-n}&-\\frac{f+n}{f-n}\\\\ 0&0&0&1 \\end{matrix} \\right) \\tag {33}&emsp;&emsp;然后又因为视锥体关于$x$轴、$y$轴对称，简化的正交投影矩阵就为： M_{projection}= \\left( \\begin{matrix} \\frac{2}{r-l}&0&0&0\\\\ 0&\\frac{2}{t-b}&0&0\\\\ 0&0&\\frac{-2}{f-n}&-\\frac{f+n}{f-n}\\\\ 0&0&0&1 \\end{matrix} \\right) \\tag {33}12345678910void Matrix4x4::setOrtho(float left, float right, float bottom, float top, float near, float far)&#123; loadIdentity(); entries[0] = 2.0f/(right-left); entries[5] = 2.0f/(top-bottom); entries[10] = -2.0f/(far-near); entries[12] = -(right+left)/(right-left); entries[13] = -(top+bottom)/(top-bottom); entries[14] = -(far+near)/(far-near);&#125; lookAt函数构造视图矩阵&emsp;&emsp;视图矩阵的工作目标是将世界坐标系中的所有物体的顶点的坐标从世界坐标系转换到摄像机坐标系。这是因为摄像机坐标系的原点不一定与世界坐标系重合，同时由于自身的旋转，坐标轴也一定不与世界坐标系的坐标轴平行。为完成工作任务，需要分为两步走：首先整体平移，将摄像机平移至世界坐标系原点，然后将顶点从世界坐标系变换至摄像机坐标系。 &emsp;&emsp;lookAt函数的输入参数分别为：$eye$摄像机的位置，$target$摄像机目标点，$up$世界空间的上向量,。首先我们要根据这些参数确定摄像机坐标系的三个轴向量，其中需要非常注意的就是变换到视图空间中时摄像机是朝向视图空间的$-Z$方向的，所以求视图空间中的$Z$轴时是摄像机的位置减去目标点的位置： Z = normalize(eye - target)\\\\ X = normalize(cross(up, Z))\\\\ Y = normalize(cross(Z,X))&emsp;&emsp;通过以上的方式我们就求出了视图空间的三条轴向量，再加上摄像机的位置我们就可以求出将世界坐标变换到与视图坐标重合的矩阵了，记为$M=T\\cdot R$，其中$T$是平移到摄像机位置$eye$的变换矩阵，$R$是旋转到摄像机坐标轴方向的旋转矩阵： M=T\\cdot R= \\left[ \\begin{matrix} 1&0&0&eye_x\\\\ 0&1&0&eye_x\\\\ 0&0&1&eye_x\\\\ 0&0&0&1 \\end{matrix} \\right] \\cdot \\left[ \\begin{matrix} X_x&Y_x&Z_x&0\\\\ X_y&Y_y&Z_y&0\\\\ X_z&Y_z&Z_z&0\\\\ 0&0&0&1 \\end{matrix} \\right] \\tag {34}&emsp;&emsp;然而公式$(34)$并不是我们要求的视图矩阵，上式中的矩阵$M$仅仅是将世界坐标轴变换到摄像机坐标轴。摄像机只是一个虚拟的物品，我们不能将上述的矩阵$M$作用于摄像机，因为摄像机根本不存在！我们视图矩阵最终作用的世界空间中的物体，这就涉及到了一个相对运动的概念！ &emsp;&emsp;当我们向前移动摄像机的时候，可以看成是摄像机不动，而物体朝着与摄像机朝向相反的方向移动。当我们向右旋转摄像机时，相当于摄像机不动而物体朝着摄像机的左边移动。摄像机的构造得益于相对于运动的理论，计算机图形学中的虚拟$3D$摄像机实际上是通过物体的移动来实现的，所以我们要构造的视图矩阵是公式$(34)$中的逆矩阵。 viewMatrix = M^{-1}=(T\\cdot R)^{-1}=R^{-1}\\cdot T^{-1} = \\left[ \\begin{matrix} X_x&Y_x&Z_x&0\\\\ X_y&Y_y&Z_y&0\\\\ X_z&Y_z&Z_z&0\\\\ 0&0&0&1 \\end{matrix} \\right]^{-1} \\cdot \\left[ \\begin{matrix} 1&0&0&eye_x\\\\ 0&1&0&eye_x\\\\ 0&0&1&eye_x\\\\ 0&0&0&1 \\end{matrix} \\right]^{-1} \\tag {35}&emsp;&emsp;由上式可知，构造视图矩阵涉及到$R$和$T$的求逆，其中的平移矩阵$T$的求逆则是直接取平移量的相反数即可： T^{-1}= \\left[ \\begin{matrix} 1&0&0&eye_x\\\\ 0&1&0&eye_x\\\\ 0&0&1&eye_x\\\\ 0&0&0&1 \\end{matrix} \\right]^{-1} = \\left[ \\begin{matrix} 1&0&0&-eye_x\\\\ 0&1&0&-eye_x\\\\ 0&0&1&-eye_x\\\\ 0&0&0&1 \\end{matrix} \\right] \\tag {36}&emsp;&emsp;至于旋转矩阵$R$，我们知道旋转矩阵都是正交矩阵，正交矩阵的一个特点就是它的逆等于它的转置： R^{-1}= \\left[ \\begin{matrix} X_x&Y_x&Z_x&0\\\\ X_y&Y_y&Z_y&0\\\\ X_z&Y_z&Z_z&0\\\\ 0&0&0&1 \\end{matrix} \\right]^{-1} = \\left[ \\begin{matrix} X_x&X_y&X_z&0\\\\ Y_x&Y_y&Y_z&0\\\\ Z_x&Z_y&Z_z&0\\\\ 0&0&0&1 \\end{matrix} \\right] \\tag {37}&emsp;&emsp;最后，我们得到视图矩阵： viewMatrix=R^{-1}\\cdot T^{-1}= \\left[ \\begin{matrix} X_x&X_y&X_z&0\\\\ Y_x&Y_y&Y_z&0\\\\ Z_x&Z_y&Z_z&0\\\\ 0&0&0&1 \\end{matrix} \\right] \\cdot \\left[ \\begin{matrix} 1&0&0&-eye_x\\\\ 0&1&0&-eye_x\\\\ 0&0&1&-eye_x\\\\ 0&0&0&1 \\end{matrix} \\right] \\\\= \\left[ \\begin{matrix} X_x&X_y&X_z&-(\\vec X\\cdot \\vec {eye})\\\\ Y_x&Y_y&Y_z&-(\\vec Y\\cdot \\vec {eye})\\\\ Z_x&Z_y&Z_z&-(\\vec Z\\cdot \\vec {eye})\\\\ 0&0&0&1 \\end{matrix} \\right] \\tag {38}1234567891011121314151617181920212223242526void Matrix4x4::setLookAt(Vector3D cameraPos, Vector3D target, Vector3D worldUp)&#123; Vector3D zAxis = cameraPos - target; zAxis.normalize(); Vector3D xAxis = worldUp.crossProduct(zAxis); xAxis.normalize(); Vector3D yAxis = zAxis.crossProduct(xAxis); yAxis.normalize(); loadIdentity(); entries[0] = xAxis.x; entries[4] = xAxis.y; entries[8] = xAxis.z; entries[1] = yAxis.x; entries[5] = yAxis.y; entries[9] = yAxis.z; entries[2] = zAxis.x; entries[6] = zAxis.y; entries[10] = zAxis.z; entries[12] = -(xAxis.dotProduct(cameraPos)); entries[13] = -(yAxis.dotProduct(cameraPos)); entries[14] = -(zAxis.dotProduct(cameraPos));&#125; 参考资料$[1]$ http://www.songho.ca/opengl/gl_projectionmatrix.html $[2]$ https://blog.csdn.net/zsq306650083/article/details/8773996 $[3]$ https://blog.csdn.net/y1196645376/article/details/78463248 $[4]$ https://www.cnblogs.com/J1ac/p/9340622.html $[5]$ https://learnopengl-cn.github.io/01%20Getting%20started/08%20Coordinate%20Systems/","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"http://yoursite.com/categories/Computer-Graphics/"},{"name":"Soft Renderer","slug":"Soft-Renderer","permalink":"http://yoursite.com/categories/Soft-Renderer/"}],"tags":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"http://yoursite.com/tags/Computer-Graphics/"},{"name":"Soft Renderer","slug":"Soft-Renderer","permalink":"http://yoursite.com/tags/Soft-Renderer/"},{"name":"3D Math","slug":"3D-Math","permalink":"http://yoursite.com/tags/3D-Math/"}]},{"title":"流体模拟基础","slug":"fluidSimulation","date":"2019-05-01T02:37:38.127Z","updated":"2019-05-01T02:14:11.978Z","comments":true,"path":"2019/05/01/fluidSimulation/","link":"","permalink":"http://yoursite.com/2019/05/01/fluidSimulation/","excerpt":"本文主要参考文献《FLUID SIMULATION SIGGRAPH 2007 Course Notes》，结合我的理解单纯地讲述一下流体渲染的一些基础知识，本人水平有限，如有错误，欢迎指出。本文只是单纯针对流体模拟领域，可能一些地方不太严谨，但是对于虚拟模拟来说是可行的。即便如此，本文涉及到大量的数学方法。","text":"本文主要参考文献《FLUID SIMULATION SIGGRAPH 2007 Course Notes》，结合我的理解单纯地讲述一下流体渲染的一些基础知识，本人水平有限，如有错误，欢迎指出。本文只是单纯针对流体模拟领域，可能一些地方不太严谨，但是对于虚拟模拟来说是可行的。即便如此，本文涉及到大量的数学方法。 矢量微积分 Naiver-Stokes偏微分方程组 N-S方程的分步求解 对流算法 一、矢量微积分&emsp;&emsp;高等数学中太多数讨论的是一维的微积分，而矢量微积分则是一维微积分的高维扩展。矢量微积分的三个基础算子：梯度（符号为$∇$），散度（符号为$∇\\cdot$)，旋度（符号为$∇\\times$），在此基础上流体力学中经常用到的还有拉普拉斯算子。 1、梯度（Gradient）&emsp;&emsp;梯度实际上就是矢量的空间偏导数，且结果依然是一个矢量，$2$维的梯度如下： ∇f(x,y)=(\\frac{\\partial f}{\\partial x},\\frac{\\partial f}{\\partial y}) \\tag {1.1}&emsp;&emsp;依此类推，$3$维的梯度有如下形式： ∇f(x,y,z)=(\\frac{\\partial f}{\\partial x},\\frac{\\partial f}{\\partial y},\\frac{\\partial f}{\\partial z}) \\tag {1.2}&emsp;&emsp;有时也会采用如下形式来表示梯度： ∇f=\\frac{\\partial f}{\\partial \\vec x} \\tag {1.3}&emsp;&emsp;梯度通常用来近似计算函数值（实际上就是一维形式的推广)： f(\\vec x+\\Delta \\vec x)\\approx f(\\vec x)+∇f(\\vec x)\\cdot \\Delta \\vec x \\tag {1.4}&emsp;&emsp;同样的，多个函数的梯度就构成了一个矩阵： ∇\\vec F=∇(f,g,h)=\\left( \\begin{matrix} \\frac{\\partial f}{\\partial x} & \\frac{\\partial f}{\\partial y} & \\frac{\\partial f}{\\partial z} \\\\ \\frac{\\partial g}{\\partial x} & \\frac{\\partial g}{\\partial y} & \\frac{\\partial g}{\\partial z} \\\\ \\frac{\\partial h}{\\partial x} & \\frac{\\partial h}{\\partial y} & \\frac{\\partial h}{\\partial z} \\\\ \\end{matrix} \\right) =\\left( \\begin{matrix}∇f\\\\ ∇g\\\\ ∇h\\\\ \\end{matrix} \\right) \\tag {1.5}2、散度（Divergence）&emsp;&emsp;散度算子仅仅应用于向量场，它衡量在某一点出相应的矢量聚集或者发散程度，测量方向为径向，结果为标量。$2$维、$3$维形式的散度算子如下所示： ∇\\cdot \\vec u=∇\\cdot (u,v)=\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y} ∇\\cdot \\vec u=∇\\cdot (u,v,w)=\\frac{\\partial u}{\\partial x}+\\frac{\\partial v}{\\partial y}+\\frac{\\partial w}{\\partial z} \\tag {1.6}&emsp;&emsp;输入是矢量，而输出为标量。类比梯度，散度符号$∇\\cdot \\vec u$可以理解为梯度$∇$与矢量$\\vec u$的点乘： ∇\\cdot \\vec u=(\\frac{\\partial}{\\partial x},\\frac{\\partial}{\\partial y},\\frac{\\partial}{\\partial z})\\cdot (u,v,w)=\\frac{\\partial}{\\partial x}u+\\frac{\\partial}{\\partial y}v+\\frac{\\partial}{\\partial z}w \\tag {1.7}&emsp;&emsp;若矢量场散度为$0$，则称该矢量场无散度。 3、旋度（Curl）&emsp;&emsp;旋度衡量围绕某一点的旋转速度，测量方向为切向，三维形式的旋度是一个向量： ∇\\times \\vec u=∇\\times (u,v,w) =(\\frac{\\partial w}{\\partial y}-\\frac{\\partial v}{\\partial z}, \\frac{\\partial u}{\\partial z}-\\frac{\\partial w}{\\partial x}, \\frac{\\partial v}{\\partial x}-\\frac{\\partial u}{\\partial y}) \\tag {1.8}&emsp;&emsp;倒推到$2$维，我们取上式中的$w=0$，即矢量场为$(u,v,0)$，$2$维向量场的旋度是一个标量： ∇\\times \\vec u=∇\\times (u,v)=\\frac{\\partial v}{\\partial x}-\\frac{\\partial u}{\\partial y} \\tag {1.9}&emsp;&emsp;同样地，旋度符号$∇\\times \\vec u$我们可以理解为梯度$∇$与矢量场$\\vec u$的叉乘： ∇\\times \\vec u= (\\frac{\\partial }{\\partial x}, \\frac{\\partial }{\\partial y}, \\frac{\\partial }{\\partial z})\\times(u,v,w) \\tag {1.10}&emsp;&emsp;若矢量场旋度为$0$，则称该矢量场无旋度。 4、拉普拉斯算子（Laplacian）&emsp;&emsp;拉普拉斯算子定义为梯度的散度，符号表示为$∇\\cdot∇$，显然$∇\\cdot$是散度，而后面的$∇$则为梯度，故拉普拉斯算子即梯度的散度，是一个二阶微分算子。$2$维、$3$维形式分别如下： ∇\\cdot∇f=\\frac{\\partial^2f}{\\partial x^2}+\\frac{\\partial^2f}{\\partial y^2} ∇\\cdot∇f=\\frac{\\partial^2f}{\\partial x^2}+\\frac{\\partial^2f}{\\partial y^2}+\\frac{\\partial^2f}{\\partial z^2} \\tag {1.11}&emsp;&emsp;简言之，拉普拉斯算子定义如下： ∇\\cdot∇f=\\Sigma_{i=1}^n\\frac{\\partial^2f}{\\partial x_i^2} \\tag {1.12}&emsp;&emsp;偏微分方程$∇\\cdot ∇f=0$被称为拉普拉斯方程；而如果右边为某个非$0$常数，即$∇\\cdot ∇f=q$，我们称之为泊松方程。更一般地，如果梯度再乘上一个标量$a$（如$1/\\rho$)，即$∇\\cdot (a∇f)=q$，我们依旧称之为泊松问题。 二、$Naiver-Stokes$偏微分方程组&emsp;&emsp;流体模拟器的构建主要围绕著名的不可压缩$Navier-Stokes$方程展开，它是一个流体力学领域的偏微分方程，方程形式如下： \\frac{\\partial \\vec u}{\\partial t}+\\vec u\\cdot ∇\\vec u+\\frac1\\rho∇p=\\vec g+\\nu∇\\cdot∇\\vec u \\tag {2.1} ∇\\cdot\\vec u=0 \\tag {2.2}&emsp;&emsp;这个方程组看起非常地复杂，接下来我们就把它剖析成一个个比较简单的部分来理解。 1、符号标记&emsp;&emsp;我们有必要定义一些物理量的符号用以标记： &emsp;&emsp;符号$\\vec u$在流体力学中通常表示为流体的速度矢量，记$3$维的速度矢量$\\vec u=(u,v,w)$； &emsp;&emsp;希腊字符$\\rho$是流体的密度，对于水，该值大约为$1000kg/m^3$，而空气则大约为$1.3kg/m^3$； &emsp;&emsp;字符$p$代表压力，流体对任何物体施加的单位面积力； &emsp;&emsp;字符$\\vec g$则是我们熟悉的重力加速度，通常取$(0,-9.81,0)m/s^2$。我们约定$y$轴向上，而$x$轴和$z$轴在水平面上。另外补充一点，我们把其他的一些类似的力都累加到$\\vec g$上，也就是我们统一用$\\vec g$表示所有类似力之和，这类力我们称之为体积力（称之为体积力是因为它们的力是作用到整个流体而不只是流体的表面）； &emsp;&emsp;希腊字符$\\nu$是流体的运动粘度，它衡量流体的黏滞性。糖蜜之类的流体有非常高的粘度，而像酒精之类的流体有很低的粘度； &emsp;&emsp;其它一些矢量微积分的符号算子前面已经提到过，不再赘述。 2、动量方程&emsp;&emsp;偏微分方程$(2.1)$我们称之为动量方程，它本质上就是我们熟悉的牛顿定律$\\vec F=m\\vec a$的形式，描述了施加在流体上的力是如何影响流体的运动。 &emsp;&emsp;假设我们用粒子系统来模拟流体，每个粒子代表流体的一小滴，每个粒子有各自的质量$m$、体积$V$和速度$\\vec u$。为了让整个粒子系统运作起来，我们必须弄清楚每个粒子所承受的力的作用。牛顿第二定律告诉我们：$\\vec F=m\\vec a$，而根据加速度定义，我们有： \\vec a=\\frac{D\\vec u}{Dt} \\tag {2.3}&emsp;&emsp;符号$D$是指物质导数，所谓物质导数，就是对流体质点求导数，而且是针对流体质点（在这里就是流体粒子）而不是空间的固定点。因而牛顿第二定律就变成： m\\frac{D\\vec u}{Dt}=\\vec F \\tag {2.4}&emsp;&emsp;那么流体粒子承受的力有哪些呢？一个最简单的力就是重力：$m\\vec g$。而其他的流体质点（或其他流体粒子）也会对当前的流体粒子产生作用力。流体内部的相互作用力之一便是压力，较大压力的区域会向较低压力区域产生作用力。值得注意的是，我们只关注施加在粒子上的压力的净合力。例如，若施加在粒子上压力在每个方向上都相等，那么它的压力的合力便为0。我们用压力的负梯度（取负是因为方向是由压力大的区域指向压力小的区域）来衡量在当前流体粒子处压力的不平衡性，即取$-∇p$。那么流体粒子所承受的压力就是对$-∇p$在整个流体粒子的体积上进行积分，为了简化，我们简单地将$V$与$-∇p$相乘，故粒子压力部分为$-V∇p$。 &emsp;&emsp;其他的流体相互作用力则是由流体的黏性产生的，我们直观地把这种力理解为尽可能使得粒子以周围区域的平均速度移动的力，也就是使得粒子的速度与周围区域粒子速度的差距最小化。拉普拉斯算子是衡量一个量与之周围区域该量平均值之差的算符，因而$∇\\cdot∇\\vec u$是当前粒子速度矢量与周围区域平均速度矢量之差。为了计算粘滞力，我们同样对$∇\\cdot∇\\vec u$在整个粒子体积$V$上进行积分，与前面类似，我们简单取$V∇\\cdot∇\\vec u$。除此之外，我们还引进一个称为动力粘度系数的物理量，符号为$\\mu$。因而粘滞力为$V\\mu∇\\cdot∇\\vec u$。 &emsp;&emsp;把重力、压力和粘滞力综合一起，我们可得： m\\frac{D\\vec u}{Dt}=\\vec F=m\\vec g-V∇p+V\\mu∇\\cdot∇\\vec u \\tag {2.5}&emsp;&emsp;当粒子系统中的粒子数量趋于无穷大，而每个粒子大小趋于$0$时，会产生一个问题：此时每个粒子的质量$m$和体积$V$变为$0$，此时上式变得没有意义。为此，我们把$(2.5)$式调整一下，两边同除以体积$V$，又因$\\rho=m/V$，故有： \\rho\\frac{D\\vec u}{Dt}=\\rho\\vec g-∇p+\\mu∇\\cdot∇\\vec u \\tag {2.6}&emsp;&emsp;两边同除以$\\rho$，移项调整： \\frac{D\\vec u}{Dt}+\\frac1\\rho∇p=\\vec g+\\frac\\mu\\rho∇\\cdot∇\\vec u \\tag {2.7}&emsp;&emsp;为了进一步简化，定义运动粘度为$\\nu=\\mu/\\rho$，式$(2.7)$变为： \\frac{D\\vec u}{Dt}+\\frac1\\rho∇p=\\vec g+\\nu∇\\cdot∇\\vec u \\tag {2.8}&emsp;&emsp;我们已经快把动量方程推导出来，现在我们要把物质导数$\\frac{D\\vec u}{Dt}$弄清楚，为此，我们需要了解两种描述方法：拉格朗日描述和欧拉描述。 3、拉格朗日描述与欧拉描述&emsp;&emsp;当我们尝试研究流体或可变形固体的运动的时候，通常有两种方法来描述：拉格朗日描述（ Lagrangian viewpoint）、欧拉描述（Eulerian viewpoint）。 &emsp;&emsp;拉格朗日描述方法是我们比较熟悉的方法，这种描述方法把物体看成是由类似于粒子系统的形式组成，固体或流体的每个点看作一个独立的粒子，粒子有各自相应的位置$\\vec x$和速度$\\vec u$。我们可以把粒子理解为组成物体的分子。对于我们通常采用拉格朗日描述法进行建模模拟，即用一系列离散的粒子集来构建，粒子之间通过网格相联系。 &emsp;&emsp;欧拉描述方法则采用了完全不同的角度，它常被用于流体力学中。与拉格朗日描述追踪每个物体粒子的方法不同，欧拉描述关注点是空间中的一个固定点，并考察在这个固定点上流体性质（如密度、速度、温度等）是如何随着时间变化的。流体流动经过这个固定点可能会导致这个固定点的物理性质发生一些变化（如一个温度较高的流体粒子流经这个固定点，后面紧跟着一个温度较低的流体粒子流过固定点，那么这个固定点的温度会降低，但是并没有任何一个流体粒子的温度发生了变化）。 &emsp;&emsp;用天气测量举个简单的例子：拉格朗日描述方法就是你乘坐在一个随风而飘的热气球上，测量周围空气的压力、密度和浑浊度等天气指标；而欧拉描述方法就是你固定在地面上，测量流过的空气的天气指标。 &emsp;&emsp;欧拉描述法似乎看起来带来了一些不必要的复杂度，但是目前大多数的流体模拟器都是基于欧拉描述法，这是因为欧拉描述法相比于拉格朗日描述法有一些不可比拟的优点：欧拉描述法能够更加方便地计算一些物理量的空间导数（例如压力梯度和粘度）；而如果用粒子方法的话（即拉格朗日描述法），那么计算物理量相对于空间位置的变化是比较难的。 &emsp;&emsp;把拉格朗日描述法和欧拉描述法联系起来的关键点就是物质导数。首先从拉格朗日描述法出发，假设有一群粒子，每个粒子都有各自的位置$\\vec x$和速度$\\vec u$。记$q$为通用的物理量（如密度、速度和温度等），每个粒子有其对应的$q$值。方程$q(t,\\vec x)$描述在时间点$t$而位置为$\\vec x$的粒子对应的物理量值$q$。则一个粒子的物理量$q$随时间$t$的变化率是多少？这是一个拉格朗日描述角度下的问题，我们取对时间$t$的导数（注意用到了求导链式法则，以及$\\frac{\\partial q}{\\partial \\vec x}=∇q$和$\\vec u=\\frac{d\\vec x}{dt}）$： \\frac d{dt}q(t,\\vec x)=\\frac{\\partial q}{\\partial t}+∇q\\cdot\\frac{d\\vec x}{dt}=\\frac{\\partial q}{\\partial t}+∇q\\cdot\\vec u\\equiv\\frac{Dq}{Dt} \\tag {2.9}&emsp;&emsp;这就是物质导数。把式$(2.9)$代入式$(2.8)$我们就得到了流体动量方程$(2.1)$。物质导数针对的是流体质点（在这里就是流体粒子）而不是空间的固定点。式$(2.9)$写完整一点就是： \\frac{Dq}{Dt}=\\frac{\\partial q}{\\partial t}+u\\frac{\\partial q}{\\partial x}+v\\frac{\\partial q}{\\partial y}+w\\frac{\\partial q}{\\partial z} \\tag {2.10}&emsp;&emsp;对于给定的速度场$\\vec u$， 流体的物理性质如何在这个速度场$\\vec u$下变化的计算我们称之为对流（advection）。一个最简单的对流方程，就是其物理量的物质导数为$0$，如下所示： \\frac{Dq}{Dt}=0\\implies\\frac{\\partial q}{\\partial t}+\\vec u\\cdot ∇q = 0 \\tag {2.11}&emsp;&emsp;公式$(2.11)$的意义即在拉格朗日视角观察下，每个流体粒子的物理量保持不变。 4、不可压缩性&emsp;&emsp;关于流体的压缩性在此不做过多的物理细节描述，只需知道一点：通常情况下流体的体积变化非常小（除开一些极端的情况，而且这些极端情况我们日常生活中较少出现）。可压缩流体的模拟涉及到非常复杂的情况，往往需要昂贵的计算资源开销，为此在计算机流体模拟中我们通常把所有的流体当作是不可压缩的，即它们的体积不会发生变化。 &emsp;&emsp;任取流体的一部分，设其体积为$\\Omega$而其边界闭合曲面为$\\partial\\Omega$，我们可以通过围绕边界曲面$\\partial\\Omega$对流体速度$\\vec u$在曲面法线方向上的分量进行积分来衡量这块部分流体的体积变化速率： \\frac d{dt}Volume(\\Omega)=\\int\\int_{\\partial\\Omega}\\vec u\\cdot n \\tag{2.12}&emsp;&emsp;对于不可压缩的流体，其体积保持为某个常量，故其体积变化速率为$0$： \\int\\int_{\\partial\\Omega}\\vec u\\cdot n=0 \\tag {2.13}&emsp;&emsp;由高斯散度定理，我们可以把式$(2.13)$转换为体积分： \\int\\int_{\\partial\\Omega}\\vec u\\cdot n=\\int\\int\\int_\\Omega∇\\cdot \\vec u=0 \\tag{2.14}&emsp;&emsp;式$(13)$应该对任意的$\\Omega$成立，意即无论$\\Omega$取何值，积分值均为$0$。这种情况下只有令积分函数值取$0$方可成立，即对$0$积分无论$\\Omega$取何值结果均为$0$。所以有： ∇\\cdot \\vec u=0 \\tag{2.15}&emsp;&emsp;这就是$Navier-Stokes$方程中的不可压缩条件$(2.2)$。满足不可压缩条件的速度场被称为是无散度的，即在该速度场下流体体积既不膨胀也不坍缩，而是保持在一个常量。模拟不可压缩流体的关键部分就是使得流体的速度场保持无散度的状态，这也是流体内部压力的来源。 &emsp;&emsp;为了把压力与速度场的散度联系起来，我们在动量方程$(2.1)$两边同时取散度： ∇\\cdot\\frac{\\partial \\vec u}{\\partial t}+∇\\cdot(\\vec u\\cdot ∇\\vec u)+∇\\cdot\\frac1\\rho∇p=∇\\cdot(\\vec g+\\nu∇\\cdot∇\\vec u) \\tag {2.16}&emsp;&emsp;对于上式$(2.16)$第一项，我们转变一下求导次序： \\frac {\\partial}{\\partial t}∇\\cdot\\vec u \\tag {2.17}&emsp;&emsp;如果满足流体不可压缩条件，那么式$(2.17)$取值$0$（因为无散度），然后我们调整一下式$(2.16)$可得关于压力的方程： ∇\\cdot\\frac1\\rho∇p=∇\\cdot(-\\vec u\\cdot ∇\\vec u+\\vec g+\\nu∇\\cdot∇\\vec u) \\tag{2.18}5、丢弃粘度项&emsp;&emsp;在某些流体如蜂蜜、小水珠等的模拟中，粘滞力起着非常重要的作用。但是在大多数流体动画模拟中，粘滞力的影响微乎其微，为此秉持着方程组越简单越好的原则，我们常常丢弃粘度项。当然这也不可避免地带来一些误差，事实上，在计算流体力学中尽可能地减少丢弃粘度项带来的误差是一个非常大的挑战。下面的叙述都是基于丢弃粘度项的前提。 &emsp;&emsp;丢弃了粘度项的$Navier-Stokes$方程被称为欧拉方程，而这种理想的流体则是无粘度的。丢弃了粘度项的欧拉方程如下： \\frac{D\\vec u}{Dt}+\\frac1\\rho∇p=\\vec g \\tag {2.19} ∇\\cdot\\vec u=0 \\tag{2.20}&emsp;&emsp;大多数的流体模拟的计算方程都是欧拉方程。 6、边界条件&emsp;&emsp;目前为止我们讨论的都是流体内部的情况，然而边界部分也是流体模拟非常关键的部分。在流体模拟中我们仅仅关注两种边界条件：固体墙（solid walls）、自由面（free surfaces）。 &emsp;&emsp;固体墙顾名思义就是流体与固体接触的边界，用速度来描述很简单：流体既不会流进固体内部也不会从固体内部流出，因此流体在固体墙法线方向上的分量为$0$： \\vec u\\cdot n=0 \\tag {2.21}&emsp;&emsp;当然，上述是固体自身不移动的情况下。通常来说，流体速度在法线方向上的分量与固体的移动速度在法线方向上的分量应该保持一致： \\vec u\\cdot n=\\vec u_{solid}\\cdot n \\tag{2.22}&emsp;&emsp;上述的两个公式都是仅对流体速度在法线方向上的分量做了限制，对于无粘度的流体，切线方向上的流体速度与固体的移动速度无必然的联系。 &emsp;&emsp;自由面是另外一个非常重要的边界条件，它通常就是与另外一种流体相接壤的边界部分。例如在模拟水花四溅时，水流表面不与固体接触的都是自由面（如与空气这种流体接触）。因空气密度远小于水导致空气对水体的仿真影响非常小，为了简化模拟，我们将空气所占的空间设为某个固定大气压的区域，设为$0$是最方便的方案，此时自由面就是压强$p=0$的水体表面。 &emsp;&emsp;在小规模的流体仿真中，自由面的表面张力占据着非常重要的地位。在微观分子层面下，表面张力的存在是因为不同的分子相互吸引产生的力。从几何的角度来解释就是，表面张力就是促使流体的表面积尽可能小的一种力。物理学上，两种不同的流体之间实际上存在着与表面平均曲率成正比的压力骤变： [p]=\\lambda k. \\tag {2.23}&emsp;&emsp;公式$(2.23)$中的$[p]$记为压力之差。$\\lambda$是表面张力系数，可以根据模拟的流体类型查找对应的张力系数（例如空气与水在室温下张力系数为$\\lambda \\approx 0.073N/m$）。而$k$就是平均曲率，单位为$m^{-1}$。又因为我们常常设空气的压力为$0$，因此水与空气交界的自由面的压力为： p=\\lambda k \\tag {2.24}​ 三、N-S方程的分步求解&emsp;&emsp;有了对以上对$Navier-Stokes$方程的理论支撑，接下来我们就要如何用计算机来对该组偏微分方程进行离散化求解。为了程序的松耦合性以及使计算尽可能地高效、简单，在流体模型领域，我们将流体方程分成几个独立的步骤，然后按顺序先后推进。对于不可压缩的无粘度流体方程（即前面的欧拉方程$(2.19)$和$(2.20)$，我们将其离散化成对流项（advection）如公式$(3.1)$、体积力项（body force）如公式$(3.2)$、压力/不可压缩项如公式$(3.3)$： \\frac{Dq}{Dt}=0 \\tag {3.1} \\frac{\\partial \\vec u}{\\partial t}=\\vec g \\tag {3.2} \\begin{cases} \\frac{\\partial \\vec u}{\\partial t}+\\frac{1}{\\rho}∇p=0\\\\ ∇\\cdot\\vec u=0 \\end{cases} \\tag {3.3}&emsp;&emsp;需要注意的是，在对流项公式$(3.1)$中我们用了一个通用量的符号$q$是因为我们不仅仅要对流体的速度进行对流，还需要对其他物理量进行对流。我们记对流项公式$(3.1)$的对流计算算法为$advect(\\vec u, \\Delta t, q)$，即对于给定的时间步长$\\Delta t$和速度场$\\vec u$，对物理量q进行对流。 &emsp;&emsp;对于体积力项$(3.2)$，我们采用简单的前向欧拉法即可：$\\vec u \\leftarrow \\vec u + g\\Delta t$。 &emsp;&emsp;对于压力/不可压缩项$(3.3)$，我们用一个称为$project(\\Delta t, \\vec u)$的算法，通过$project(\\Delta t, \\vec u)$计算出正确的压力以确保速度场$\\vec u$的无散度性质。欧拉方案不会着重研究具体粒子间的作用力，因而不会正向去求解$\\frac{1}{\\rho}∇p$，它是利用流体不可压缩的特性，将速度场$\\vec u$投影到散度为$0$的空间上，间接地解算了压力项。这种思想相当于，已知一个中间量$\\vec u_{temp}$，对这个中间量的唯一一个操作（如正向求解压力$\\frac{1}{\\rho}∇p$）不可行，但是直到最终量$\\vec u_{fianl}$符号的一个性质（散度为$0$），于是只要将$\\vec u_{temp}$投影到符合散度为$0$的特性平面上，即可间接地还原正向求解压力的操作，得到最终的速度场$\\vec u_{temp}$。 &emsp;&emsp;对流项$advect(\\vec u, \\Delta t, q)$的输入速度场$\\vec u$要确保为无散度的状态，投影项$project(\\Delta t, \\vec u)$确保了流体体积保持不变，因而投影项输出的速度场必然是无散度的。所以我们只要确保投影项$project(\\Delta t, \\vec u)$输出的速度场$\\vec u$作为对流项$advect(\\vec u, \\Delta t, q)$的输入即可，这时我们的分步求解流体方程的优势就体现出来了，其伪代码如下所示。 算法1 Fluid Simulation($\\vec u_n$, $\\Delta t$): 1: 初始化速度场$\\vec u_n$,使得$\\vec u_n$无散度 2: 对于每个时间步$n = 0,1,2,…$ 3: &emsp;&emsp;决定一个合理的时间步长$\\Delta t = t_{n+1}-t_n$ 4: &emsp;&emsp;对流项计算$\\vec u_A=advect(\\vec u_n,\\Delta t,\\vec q)$ 5: &emsp;&emsp;体积力项计算$\\vec u_B=\\vec u_A+\\Delta t\\vec g$ 6: &emsp;&emsp;无散度投影$\\vec u_{n+1}=project(\\Delta t,\\vec u_B)$ 1、时间步长&emsp;&emsp;在流体模拟算法中，确定适当的时间步长是算法的第一步。因为计算流体模拟的最后结果是呈现在屏幕上的，所以$\\Delta t$的选取与屏幕的刷新率有重要的关系。若选取的$\\Delta t$有$t_n+\\Delta t &gt; t_{frame}$，那么必须做一个截断使$\\Delta t=t_{frame}-t_n$。此外，流体模拟的三个步骤即对流项、体积力项、无散度投影项对时间步长$\\Delta t$的要求不尽相同，要选择一个满足所有要求的最小时间步长能确保计算的收敛性。此外，一方面为了流体模拟的真实性，我们可能需要选取一个足够小的时间步长来复现流体的高质量细节。另一方面，有时高性能的需求又使得我们不能选取太小的时间步长去渲染一帧。假设一帧至少要进行三个时间步的模拟，那么$\\Delta t$应该至少设成帧间隔时间的三分之一。 2、网格结构&emsp;&emsp;欧拉法的整个流程都是基于网格的，所以合理的网格结构是算法高效的关键点。$Harlow$和$Welch$提出了一种经典的$MAC$（marker and cell）网格结构，许多不可压缩流体模拟的算法都在这个网格结构上呈现出了良好的效率。$MAC$网格是一种交叉排列的网格，不同类型的物理量被存储于网格的不同位置。以二维的网格为例，如图3-1左图所示，流体粒子的压力数据存储于网格的中心点$P_{i,j}$，而速度则沿着笛卡尔坐标被分成了两部分。水平方向的$u$成分被存储在了网格单元竖直边的中心处，例如网格单元$(i,j)$和$(i+1,j)$之间的水平速度记为$u_{i+1/2,j}$。垂直方向的$v$成分则被存储在了网格单元水平面的中心上。这样的存储方案十分有利于估算流体流进/流出某个网格单元的量。 图3-1 MAC网格,左图二维,右图三维 &emsp;&emsp;扩展到三维的情况，$MAC$网格同样是交错排列的结构网格，如图3-1右图所示。压力数值存储在立方体网格单元的中心，三个速度分量分别被记录在立方体网格单元的三个表面的中心点上。在数值计算时，这样的分配方式使得我们可以准确地采用中心差分法计算压力梯度和速度的散度，同时克服了中心差分法的一个普遍的缺点。一维的情况为例，在网格顶点位置$…,q_{i-1},q_i,q_{i+1}…$上估算量场$q$的导数，为了无偏（所谓无偏，就是不偏向左边或者右边）估计网格顶点$i$处的$\\frac{\\partial q}{\\partial x}$，一种比较自然的方式就是采用一阶中心差分法： (\\frac{\\partial q}{\\partial x})_i\\approx \\frac{q_{i+1}-q_{i-1}}{2\\Delta x} \\tag {3.4}&emsp;&emsp;公式$(3.4)$是无偏的，且精确度为$O(\\Delta x^2)$。而前向欧拉差分法偏向右边且精确度只有$O(\\Delta x)$： (\\frac{\\partial q}{\\partial x})_i\\approx \\frac{q_{i+1}-q_i}{\\Delta x} \\tag {3.5}&emsp;&emsp;然而，公式$(3.4)$存在着一个非常严重的问题：网格点$i$的估算导数完全忽略了$q_i$的值。数学上，只有常数函数的一阶导数为零。但是公式$(3.4)$遇到了锯齿函数如$q_i=(-1)^i$时，它错误地将该类函数的导数估算为$0$，这种问题被称为零空间问题（null-space problem）。 &emsp;&emsp;交叉错排的$MAC$网格完美地克服了中心差分法的零空间问题，同时也保持了它的无偏二阶精度。在$MAC$网格上运用中心差分法，网格点$i$处的估算导数公式如下所示： (\\frac{\\partial q}{\\partial x})_i\\approx\\frac{q_{i+1/2}-q_{i-1/2}}{\\Delta x} \\tag {3.6}&emsp;&emsp;$MAC$网格确实给流体的压力计算和不可压缩性的处理带来了很大的便利，但与此同时也带来了一些其他方面的麻烦。如果我们要估算某个地方的速度向量，即便采样点恰好在网格点上我们也要做一些插值才能获取相应的速度向量。在网格点处，我们通常采用平均法，以二维为例： \\vec u_{i,j}=(\\frac{u_{i-1/2,j}+u_{i+1/2,j}}{2},\\frac{v_{i,j-1/2}+v_{i,j+1/2}}{2}),\\\\ \\vec u_{i+1/2,j}=(u_{i+1/2,j},\\frac{v_{i,j-1/2}+v_{i,j+1/2}+v_{i+1,j-1/2}+v_{i+1,j+1/2}}{4}),\\\\ \\vec u_{i,j+1/2}=(\\frac{u_{i-1/2,j}+u_{i+1/2,j}+u_{i-1/2,j+1}+u_{i+1/2,j+1}}{4},v_{i,j+1/2}).\\tag {3.7}&emsp;&emsp;最后，在实现中下标索引一般没有浮点数之说，前面直接采用$i+1/2$的记法是为了便于叙述。一般约定如下： p(i,j,k)=p_{i,j,k},\\\\ u(i,j,k)=u_{i-1/2,j,k},\\\\ v(i,j,k)=v_{i,j-1/2,k},\\\\ w(i,j,k)=w_{i,j,k-1/2}. \\tag{3.8}&emsp;&emsp;因而对于$nx\\times ny\\times nz$分辨率的网格，压力数值存储在$nx\\times ny\\times nz$的数组中，速度的$u$成分存储在$(nx+1)\\times ny\\times nz$数组中，速度的$v$成分存储在$nx\\times (ny+1)\\times nz$数组中，速度的$w$成分存储在$nx\\times ny\\times (nz+1)$数组中。 四、对流算法&emsp;&emsp;求解如下所示的对流方程是流体模拟的关键一步： \\frac{Dq}{Dt}=0 \\tag {4.1}&emsp;&emsp;我们把这个对流数值计算的算法记为： q^{n+1}=advect(\\vec u,\\Delta t,q^n) \\tag {4.2}&emsp;&emsp;公式$(4.2)$中的各个符号含义： &emsp;&emsp;$\\vec u$：在$MAC$网格上的离散化的速度场； &emsp;&emsp;$\\Delta t$：时间步长； &emsp;&emsp;$q^n$：当前的物理量场$q$（如流体密度、速度、燃烧物浓度等）； &emsp;&emsp;$q^{n+1}$：经过对流后得到的新的量场。 &emsp;&emsp;在这里要特别注意，输入对流算法的速度场$\\vec u$必须是无散度的，否则模拟结果会出现一些奇怪的失真现象。 1、半拉格朗日对流算法（Semi-Lagrangian Advection）&emsp;&emsp;一维情况下，对流方程$(4.1)$写成偏微分的形式如下： \\frac{\\partial q}{\\partial t}+u\\frac{\\partial q}{\\partial x}=0 \\tag {4.3}&emsp;&emsp;分别采用前向欧拉差分法计算对时间的偏导和中心差分法计算对空间的偏导，我们有： \\frac{q^{n+1}_{i}-q^n_i}{\\Delta t}+u^n_i\\frac{q^n_{i+1}-q^n_{i-1}}{2\\Delta x}=0 \\tag {4.4}&emsp;&emsp;转成以$q^{n+1}_i$为计算目标的显式公式，得： q^{n+1}_i=q^n_i-\\Delta t u^n_i\\frac{q^n_{i+1}-q^n_{i-1}}{2\\Delta x} \\tag {4.5}&emsp;&emsp;公式$(4.5)$看起来没什么问题，但是却存在非常严重的漏洞。首先，前向欧拉法被证明是无条件不稳定的空间离散方法：无论取多么小Δ𝑡，随着时间步的推进，累积误差终将发散。即使使用更稳定的时间积分方法来取代前向欧拉方法，解决了时间上的PDE（Partial Differential Equation，偏微分方程）计算，空间上的PDE计算还是会带来重大的麻烦。标准中心差分方法不可避免地会出现的零空间问题，具有高频震荡性质的速度场对空间的导数被错误地计算为$0$或几乎为$0$，低离速度分量被分离出来，从而导致模拟效果中出现许多奇怪的高频摆动和震荡。 &emsp;&emsp;针对这些问题，研究者们提出了一个解然不同的、更加简单和更具物理直观意义的半拉格朗日法。之所以叫半拉格朗日法，是因为这种方法是以拉格朗日视角去解决欧拉视角的对流方程（“半”字的由来）。假设我们的目标是求解网格点$\\vec x_G$的在第$n+1$个时间步时关于物理量$q$的新值，记为$q^{n+1}_G$。在拉格朗日的视角下，我们可以寻找在第$n+1$时间步之前，是空间中的哪一个点上的流体粒子在速度场$\\vec u$的作用下“流向”了$\\vec x_G$，我们记这个粒子在第$n$个时间步时的网格位置为$\\vec x_P$，则第$n+1$个时间步时$\\vec x_G$的$q^{n+1}_G$即为第$n$个时间步时$\\vec x_P$的$q^{n}_P$。如下图4-1为半拉格朗日对流法的示意图。 图4-1 半拉格朗日对流法 &emsp;&emsp;半拉格朗日对流法的第一步就是要找出$\\vec x_P$，为此我们根据$\\vec x_G$做反向的追踪。粒子位置对时间的导数就是速度场： \\frac{d\\vec x}{dt}=\\vec u(\\vec x) \\tag {4.6}&emsp;&emsp;经过一个时间步长$\\Delta t$之后，粒子由$\\vec x_P$移动到$\\vec x_G$。为了得到$\\vec x_P$，最简单的方法就是采用前向欧拉法进行倒推： \\vec x_P=\\vec x_G-\\Delta t\\vec u(\\vec x_G) \\tag {4.7}&emsp;&emsp;然而前向欧拉法只有一阶的精度，若在不改变$\\Delta t$的情况下提高精度，我们可以采用高阶的龙格库塔法（Runge-Kutta method）。采用二阶的龙格库塔法如下所示： \\vec x_{mid}=\\vec x_G-\\frac12\\Delta t\\vec u(\\vec x_G),\\\\ \\vec x_P=\\vec x_G-\\Delta t\\vec u(\\vec x_{mid}). \\tag {4.7}&emsp;&emsp;倒推得到$\\Delta t$之前的网格位置$\\vec x_P$一般不会恰好在网格顶点上，为此我们需要做些插值。三维模拟通常采用三线性插值，而二维的则采用双线性插值。 q^{n+1}_G=interpolate(q_n,\\vec x_P) \\tag {4.8}2、边界情况&emsp;&emsp;若我们倒推得到的$\\vec x_P$仍然在流体的内部，那么做插值是完全没问题的。但若$\\vec x_P$在流体的边界之外呢？这种情况的出现的原因通常有两个：一个是$\\vec x_P$确确实实在流体的外部且即将流入流体内部，另一个是由前向欧拉法或龙格库塔法的数值计算方法带来的误差导致。 &emsp;&emsp;在一种情况下，我们应该知道当流体流入时其携带的物理量，此时我们将这个外部流入的物理量作为返回值即可。例如，第$n$个时间步时的外部流体以速度$\\vec U$和温度$T$在第$n+1$个时间步时注入流体内部$\\vec x_G$的位置，那么$\\vec T^{n+1}_G$的值就为$T$。 &emsp;&emsp;在第二种由误差导致的情况下，一个适当的策略就是根据边界上的最近点外推出所求得物理量。在模拟某些流体时，外推变得很简单。例如，在模拟烟雾时我们简单地假设烟雾流体外部即空气的速度风场为某个常数$\\vec U$（可能为$0$），这样边界上的速度场都取$\\vec U$。但还有一些必须根据流体内部的已知量外推出未知量，这时情况就变得比较复杂了。具体如何外推将在后面介绍，目前我们只需要知道大概的步骤：首先寻找边界上的最近点，然后在最近点的领域内插值获取相应的物理量场。 3、时间步长大小&emsp;&emsp;对任何一种数值计算方法的主要的考虑点就是它是否稳定。幸运的是，半拉格朗日对流法已经被证明是一种无条件稳定的算法：无论$\\Delta t$取多大，它永远不会出现数值爆炸的现象。因为每一个新值$q$的确定，都是通过对旧值得插值，无论是线性插值、双线性插值还是三线性插值，$q$的大小都是处于插值点之间，不会得到比原来插值点更大或者更小的值，因而$q$是有上下界的。这使得我们可以尽情地根据所需的模拟质量和模拟效率去调整时间步长。 &emsp;&emsp;但是在实践中，时间步长的大小也不能选得太过极端，否则会产生一些奇观的现象。Foster和Fekiw提出了一个对$\\Delta t$的限制：流体粒子在$\\Delta t$内的倒推轨迹最多经过某个常数个网格单元为宜，例如5个： \\Delta t \\leq \\frac{5\\Delta x}{u_{max}} \\tag {4.9}&emsp;&emsp;公式$(4.9)$中，$u_{max}$是速度场的最大值，我们可以简单地取 存储在网格中的最大速度值。一个更鲁棒的方法考虑了体积力（如重力、浮力等）对最大速度的影响： u_{max}=max(|u^n|)+\\Delta t|g| \\tag {4.10}&emsp;&emsp;将不等式$(4.9)$的最大值带入公式$(4.10)$，我们有： u_{max}=max(|u^n|)+\\frac{5\\Delta x}{u_{max}}|g| \\tag {4.11}&emsp;&emsp;取一个简单的速度上界（简化了公式$(4.11)$），$u_{max}$： u_{max}=max(|u^n|)+\\sqrt{5\\Delta xg} \\tag {4.12}&emsp;&emsp;这样确保了$u_{max}$始终为正，且避免公式$(4.9)$的除$0$错误。 &emsp;&emsp;关于时间步长的讨论离不开$CFL$（以Courant、Friedrichs、Lewy三人的名字命名）条件。$CFL$条件是一个简单而直观的判断计算是否收敛的必要条件。它的直观物理解释就是时间推进求解的速度必须大于物理扰动传播的速度，只有这样才能将物理上所有的扰动俘获到。满足$CFL$条件意味着当$\\Delta x$和$\\Delta t$趋于取极限$0$时，数值计算所求的解就会收敛到原微分方程的解。 &emsp;&emsp;对于半拉格朗日对流法，其满足$CFL$条件当且仅当在极限情况下，追踪得到的粒子轨迹足够逼近真实的轨迹。足够逼近的意思是经过正确的网格插值能够得到正确的依赖域（即差分格式的依赖域包含了原微分方程的依赖域），追踪的轨迹就会收敛到正确真实的轨迹。 &emsp;&emsp;因而，对于采用标准的显式有限差分法的对流方程求解，为了保证收敛，我们要求$q^{n+1}$的新值是由以当前网格点为中心、以$C\\Delta x$（$C$是一个小的整数常量）为半径的邻域范围内插值得到： \\Delta t \\leq C\\frac{\\Delta x}{|\\vec u|} \\tag {4.13}&emsp;&emsp;公式$(4.13)$中的$C$被称为$CFL$数，因而不等式$(4.9)$可以看成是公式$(4.13)$取$CFL$数为$5$得到。 4、数值耗散&emsp;&emsp;对流算法在对流获取新的物理量场$q^{n+1}_i$时会进行一些插值操作，插值不可避免地会平滑物理量场，这带来了一些数值耗散。一次两次的数值耗散不会由太大的影响，但是在流体模拟中我们会在每个时间步都进行对流运算，反反复复的平滑操作将数值耗散不断扩大，损失大量的流体细节。 &emsp;&emsp;以一维的对流项计算为例，流体速度为常量$u&gt;0$： \\frac{\\partial q}{\\partial t}+u\\frac{\\partial q}{\\partial x}=0 \\tag {4.14}&emsp;&emsp;假设$\\Delta t &lt; \\frac{\\Delta x}{u}$，即单个时间步长内粒子追踪轨迹长度小于单个网格单元的大小。我们的目标点是$x_i$，则倒推得到的粒子位置就落在了$[x_{i-1},x_i]$上的$x_i-\\Delta tu$，然后进行线性插值得到$q^{n+1}_i$： q^{n+1}=\\frac{\\Delta tu}{\\Delta x}q^n_{i-1}+(1-\\frac{\\Delta tu}{\\Delta x})q^n_i \\tag {4.15}&emsp;&emsp;将公式$(4.15)$整理一下，有： q^{n+1}_i=q^n_i-\\Delta tu\\frac{q^n_i-q^n_{i-1}}{\\Delta x} \\tag {4.16}&emsp;&emsp;公式$(4.16)$实际上正好就是采用时间上的前向欧拉差分法和空间上的单向有限差分法的欧拉方案，把$q^n_i$看成是$q^n$关于$x_i$的函数，对$q^n_{i-1}$进行泰勒级数展开： q^n_{i-1}=q^n_i-(\\frac{\\partial q}{\\partial x})^n_i\\Delta x+(\\frac{\\partial^2q}{\\partial x^2})^n_i\\frac{\\Delta x^2}{2}+O(\\Delta x^3) \\tag {4.17}&emsp;&emsp;将公式$(4.17)$代入公式$(4.16)$，并做一些变量消去，可得： q^{n+1}_i=q^n_i-\\Delta tu(\\frac{\\partial q}{\\partial x})^n_i+\\Delta tu\\Delta x(\\frac{\\partial^2q}{\\partial x^2})^n_i+O(\\Delta x^2) \\tag {4.18}&emsp;&emsp;在二阶截断误差的情况下，结合公式$(4.18)$和公式$(4.14)$，有： \\frac{\\partial q}{\\partial t}+u\\frac{\\partial q}{\\partial x}=u\\Delta x(\\frac{\\partial^2q}{\\partial x^2}) \\tag {4.19}&emsp;&emsp;右边就是对流方程计算时引入的额外类似粘度乘上系数$u\\Delta x$的项。这也就是说，当我们采用简单的半拉格朗日法去求解无粘度的对流方程时，模拟的结果却看起来我们像时在模拟有粘度的流体。这就是数值耗散！当然，当$\\Delta x\\to 0$时，这个数值耗散系数也会趋于$0$，所以取时间步无穷小时能够得到正确的模拟结果，但这需要耗费巨额的计算资源开销。我们通常模拟的流体大多数都是无粘度的，所以如何减少这个数值耗散是个至关重要的难题。 &emsp;&emsp;一个简单有效的修复数值耗散的方法就是采用更加锐利的插值方法，从而尽可能地减少由插值带来的数值耗散。在一维的情况时，我们采用三次插值（cubic interpolant）如下公式$(4.21)$，而不是简单的一次线性插值$(4.20)$： q\\approx(1-s)x_i+sx_{i+1} \\tag {4.20} q\\approx[-\\frac13s+\\frac12s^2-\\frac16s^3]q_{i-1}+[1-s^2+\\frac12(s^3-s)]q_i\\\\ +[s+\\frac12(s^2-s^3)]q_{i+1}+[\\frac16(s^3-s)]q_{i+2} \\tag {4.21}&emsp;&emsp;扩展到二维或者三维就是双三次插值（bicubic interpolation）或三三次插值（tricubic interpolation）。以二维情况为例，我们可以先沿着$x$轴做第一遍的三次插值如公式$(4.22)$，然后再沿着$y$轴做第二遍插值如公式$(4.23)$： q_{j-1}=w_{-1}(s)q_{i-1,j-1}+w_0(s)+q_{i,j-1}+w_1(s)q_{i+1,j-1}+w_2(s)q_{i+2,j-1},\\\\ q_{j}=w_{-1}(s)q_{i-1,j}+w_0(s)+q_{i,j}+w_1(s)q_{i+1,j}+w_2(s)q_{i+2,j},\\\\ q_{j+1}=w_{-1}(s)q_{i-1,j+1}+w_0(s)+q_{i,j+1}+w_1(s)q_{i+1,j+1}+w_2(s)q_{i+2,j+1},\\\\ q_{j+2}=w_{-1}(s)q_{i-1,j+2}+w_0(s)+q_{i,j+2}+w_1(s)q_{i+1,j+2}+w_2(s)q_{i+2,j+2}. \\tag {4.22} q=w_{-1}(t)q_{j-1}+w_0(t)q_j+w_1(t)q_{j+1}+w_2(t)q_{j+2} \\tag {4.23}&emsp;&emsp;当然也可以先沿着$y$轴，然后再沿着$x$轴做插值操作。","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"http://yoursite.com/categories/Computer-Graphics/"},{"name":"Fluid Simulation","slug":"Fluid-Simulation","permalink":"http://yoursite.com/categories/Fluid-Simulation/"}],"tags":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"http://yoursite.com/tags/Computer-Graphics/"},{"name":"Naiver-Stokes Equations","slug":"Naiver-Stokes-Equations","permalink":"http://yoursite.com/tags/Naiver-Stokes-Equations/"},{"name":"Fluid Simulation","slug":"Fluid-Simulation","permalink":"http://yoursite.com/tags/Fluid-Simulation/"},{"name":"Advection","slug":"Advection","permalink":"http://yoursite.com/tags/Advection/"}]}]}